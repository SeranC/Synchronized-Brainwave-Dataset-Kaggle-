{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r subjects\n",
    "%store -r eeg_final\n",
    "%store -r stimulus\n",
    "%store -r master_df\n",
    "%store -r master_time\n",
    "%store -r master_label_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>indra_time</th>\n",
       "      <th>browser_latency</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>attention_esense</th>\n",
       "      <th>meditation_esense</th>\n",
       "      <th>eeg_power</th>\n",
       "      <th>raw_values</th>\n",
       "      <th>signal_quality</th>\n",
       "      <th>...</th>\n",
       "      <th>low_beta</th>\n",
       "      <th>high_beta</th>\n",
       "      <th>low_gamma</th>\n",
       "      <th>mid+gamma</th>\n",
       "      <th>Session</th>\n",
       "      <th>Seen video before?</th>\n",
       "      <th>Chosen color</th>\n",
       "      <th>Saw icons?</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Wear contacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>27618</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-05-09 23:32:41.663</td>\n",
       "      <td>-38</td>\n",
       "      <td>2015-05-09 16:32:41.788</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>[741016.0, 1068203.0, 253428.0, 112710.0, 1715...</td>\n",
       "      <td>[49.0, 61.0, 92.0, 91.0, 56.0, 25.0, 25.0, 53....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>171571.0</td>\n",
       "      <td>138093.0</td>\n",
       "      <td>19539.0</td>\n",
       "      <td>13687.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>27619</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-05-09 23:32:42.571</td>\n",
       "      <td>-39</td>\n",
       "      <td>2015-05-09 16:32:42.789</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>[9416.0, 13022.0, 18955.0, 15597.0, 8903.0, 20...</td>\n",
       "      <td>[27.0, 39.0, 65.0, 92.0, 103.0, 84.0, 70.0, 75...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8903.0</td>\n",
       "      <td>20473.0</td>\n",
       "      <td>5763.0</td>\n",
       "      <td>7271.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>27620</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-05-09 23:32:43.481</td>\n",
       "      <td>-39</td>\n",
       "      <td>2015-05-09 16:32:43.755</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>[116550.0, 7062.0, 10241.0, 2245.0, 4162.0, 65...</td>\n",
       "      <td>[58.0, 17.0, 3.0, 39.0, 96.0, 117.0, 99.0, 73....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4162.0</td>\n",
       "      <td>6597.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>4858.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>27621</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-05-09 23:32:44.698</td>\n",
       "      <td>-39</td>\n",
       "      <td>2015-05-09 16:32:44.758</td>\n",
       "      <td>93</td>\n",
       "      <td>83</td>\n",
       "      <td>[13884.0, 5769.0, 8625.0, 1837.0, 6221.0, 2283...</td>\n",
       "      <td>[124.0, 101.0, 67.0, 75.0, 106.0, 99.0, 66.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6221.0</td>\n",
       "      <td>22838.0</td>\n",
       "      <td>11360.0</td>\n",
       "      <td>13625.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>27622</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-05-09 23:32:45.609</td>\n",
       "      <td>-39</td>\n",
       "      <td>2015-05-09 16:32:45.742</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>[701748.0, 51032.0, 24760.0, 6768.0, 3128.0, 8...</td>\n",
       "      <td>[132.0, 141.0, 154.0, 155.0, 137.0, 104.0, 80....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3128.0</td>\n",
       "      <td>8376.0</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>3705.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26443</th>\n",
       "      <td>18015</td>\n",
       "      <td>27</td>\n",
       "      <td>2015-05-09 23:48:48.296</td>\n",
       "      <td>-938</td>\n",
       "      <td>2015-05-09 16:48:49.516</td>\n",
       "      <td>84</td>\n",
       "      <td>29</td>\n",
       "      <td>[34004.0, 9627.0, 3836.0, 9513.0, 8240.0, 8078...</td>\n",
       "      <td>[39.0, 52.0, 44.0, 44.0, 59.0, 55.0, 35.0, 21....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8240.0</td>\n",
       "      <td>80781.0</td>\n",
       "      <td>39374.0</td>\n",
       "      <td>16310.0</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>m</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26444</th>\n",
       "      <td>18016</td>\n",
       "      <td>27</td>\n",
       "      <td>2015-05-09 23:48:49.516</td>\n",
       "      <td>-939</td>\n",
       "      <td>2015-05-09 16:48:50.536</td>\n",
       "      <td>74</td>\n",
       "      <td>20</td>\n",
       "      <td>[1602302.0, 202666.0, 40488.0, 38347.0, 5081.0...</td>\n",
       "      <td>[117.0, 118.0, 67.0, 25.0, -5.0, -29.0, -39.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5081.0</td>\n",
       "      <td>26990.0</td>\n",
       "      <td>21178.0</td>\n",
       "      <td>15716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>m</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26445</th>\n",
       "      <td>18017</td>\n",
       "      <td>27</td>\n",
       "      <td>2015-05-09 23:48:50.433</td>\n",
       "      <td>-939</td>\n",
       "      <td>2015-05-09 16:48:51.534</td>\n",
       "      <td>67</td>\n",
       "      <td>23</td>\n",
       "      <td>[634272.0, 336226.0, 67494.0, 17244.0, 8897.0,...</td>\n",
       "      <td>[67.0, 40.0, -4.0, -24.0, 5.0, 67.0, 106.0, 92...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8897.0</td>\n",
       "      <td>33338.0</td>\n",
       "      <td>49510.0</td>\n",
       "      <td>12804.0</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>m</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26446</th>\n",
       "      <td>18018</td>\n",
       "      <td>27</td>\n",
       "      <td>2015-05-09 23:48:51.346</td>\n",
       "      <td>-939</td>\n",
       "      <td>2015-05-09 16:48:52.522</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "      <td>[109181.0, 46985.0, 15022.0, 17584.0, 15259.0,...</td>\n",
       "      <td>[684.0, 620.0, 565.0, 552.0, 541.0, 553.0, 577...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15259.0</td>\n",
       "      <td>124133.0</td>\n",
       "      <td>19728.0</td>\n",
       "      <td>11153.0</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>m</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26447</th>\n",
       "      <td>18019</td>\n",
       "      <td>27</td>\n",
       "      <td>2015-05-09 23:48:52.567</td>\n",
       "      <td>-938</td>\n",
       "      <td>2015-05-09 16:48:53.527</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>[1357718.0, 8132.0, 5568.0, 5254.0, 2544.0, 46...</td>\n",
       "      <td>[3.0, 23.0, 19.0, -1.0, 8.0, 48.0, 64.0, 42.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>4656.0</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>r</td>\n",
       "      <td>both</td>\n",
       "      <td>m</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7406 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  id              indra_time browser_latency  \\\n",
       "677         27618   8 2015-05-09 23:32:41.663             -38   \n",
       "678         27619   8 2015-05-09 23:32:42.571             -39   \n",
       "679         27620   8 2015-05-09 23:32:43.481             -39   \n",
       "680         27621   8 2015-05-09 23:32:44.698             -39   \n",
       "681         27622   8 2015-05-09 23:32:45.609             -39   \n",
       "...           ...  ..                     ...             ...   \n",
       "26443       18015  27 2015-05-09 23:48:48.296            -938   \n",
       "26444       18016  27 2015-05-09 23:48:49.516            -939   \n",
       "26445       18017  27 2015-05-09 23:48:50.433            -939   \n",
       "26446       18018  27 2015-05-09 23:48:51.346            -939   \n",
       "26447       18019  27 2015-05-09 23:48:52.567            -938   \n",
       "\n",
       "                 reading_time  attention_esense  meditation_esense  \\\n",
       "677   2015-05-09 16:32:41.788                64                 67   \n",
       "678   2015-05-09 16:32:42.789                80                 83   \n",
       "679   2015-05-09 16:32:43.755                90                 90   \n",
       "680   2015-05-09 16:32:44.758                93                 83   \n",
       "681   2015-05-09 16:32:45.742                91                 90   \n",
       "...                       ...               ...                ...   \n",
       "26443 2015-05-09 16:48:49.516                84                 29   \n",
       "26444 2015-05-09 16:48:50.536                74                 20   \n",
       "26445 2015-05-09 16:48:51.534                67                 23   \n",
       "26446 2015-05-09 16:48:52.522                66                 24   \n",
       "26447 2015-05-09 16:48:53.527                44                 43   \n",
       "\n",
       "                                               eeg_power  \\\n",
       "677    [741016.0, 1068203.0, 253428.0, 112710.0, 1715...   \n",
       "678    [9416.0, 13022.0, 18955.0, 15597.0, 8903.0, 20...   \n",
       "679    [116550.0, 7062.0, 10241.0, 2245.0, 4162.0, 65...   \n",
       "680    [13884.0, 5769.0, 8625.0, 1837.0, 6221.0, 2283...   \n",
       "681    [701748.0, 51032.0, 24760.0, 6768.0, 3128.0, 8...   \n",
       "...                                                  ...   \n",
       "26443  [34004.0, 9627.0, 3836.0, 9513.0, 8240.0, 8078...   \n",
       "26444  [1602302.0, 202666.0, 40488.0, 38347.0, 5081.0...   \n",
       "26445  [634272.0, 336226.0, 67494.0, 17244.0, 8897.0,...   \n",
       "26446  [109181.0, 46985.0, 15022.0, 17584.0, 15259.0,...   \n",
       "26447  [1357718.0, 8132.0, 5568.0, 5254.0, 2544.0, 46...   \n",
       "\n",
       "                                              raw_values  signal_quality  ...  \\\n",
       "677    [49.0, 61.0, 92.0, 91.0, 56.0, 25.0, 25.0, 53....               0  ...   \n",
       "678    [27.0, 39.0, 65.0, 92.0, 103.0, 84.0, 70.0, 75...               0  ...   \n",
       "679    [58.0, 17.0, 3.0, 39.0, 96.0, 117.0, 99.0, 73....               0  ...   \n",
       "680    [124.0, 101.0, 67.0, 75.0, 106.0, 99.0, 66.0, ...               0  ...   \n",
       "681    [132.0, 141.0, 154.0, 155.0, 137.0, 104.0, 80....               0  ...   \n",
       "...                                                  ...             ...  ...   \n",
       "26443  [39.0, 52.0, 44.0, 44.0, 59.0, 55.0, 35.0, 21....               0  ...   \n",
       "26444  [117.0, 118.0, 67.0, 25.0, -5.0, -29.0, -39.0,...               0  ...   \n",
       "26445  [67.0, 40.0, -4.0, -24.0, 5.0, 67.0, 106.0, 92...               0  ...   \n",
       "26446  [684.0, 620.0, 565.0, 552.0, 541.0, 553.0, 577...               0  ...   \n",
       "26447  [3.0, 23.0, 19.0, -1.0, 8.0, 48.0, 64.0, 42.0,...               0  ...   \n",
       "\n",
       "       low_beta high_beta low_gamma  mid+gamma  Session  Seen video before?  \\\n",
       "677    171571.0  138093.0   19539.0    13687.0        1                   n   \n",
       "678      8903.0   20473.0    5763.0     7271.0        1                   n   \n",
       "679      4162.0    6597.0    1435.0     4858.0        1                   n   \n",
       "680      6221.0   22838.0   11360.0    13625.0        1                   n   \n",
       "681      3128.0    8376.0    4160.0     3705.0        1                   n   \n",
       "...         ...       ...       ...        ...      ...                 ...   \n",
       "26443    8240.0   80781.0   39374.0    16310.0        2                   y   \n",
       "26444    5081.0   26990.0   21178.0    15716.0        2                   y   \n",
       "26445    8897.0   33338.0   49510.0    12804.0        2                   y   \n",
       "26446   15259.0  124133.0   19728.0    11153.0        2                   y   \n",
       "26447    2544.0    4656.0    1273.0     1726.0        2                   y   \n",
       "\n",
       "       Chosen color  Saw icons?  Gender  Wear contacts  \n",
       "677               r        both       f              n  \n",
       "678               r        both       f              n  \n",
       "679               r        both       f              n  \n",
       "680               r        both       f              n  \n",
       "681               r        both       f              n  \n",
       "...             ...         ...     ...            ...  \n",
       "26443             r        both       m              n  \n",
       "26444             r        both       m              n  \n",
       "26445             r        both       m              n  \n",
       "26446             r        both       m              n  \n",
       "26447             r        both       m              n  \n",
       "\n",
       "[7406 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC(kernel='linear', C=1, random_state = 101)\n",
    "# for i in range(1,31):\n",
    "#     subject = master_time[master_time['id'] == i]\n",
    "#     features = subject.drop(['id', 'label'], axis = 1)\n",
    "#     scores = cross_val_score(svm, features, subject['label'], \n",
    "#                              cv = 5, scoring = 'accuracy')  \n",
    "#     mean_score = scores.mean()\n",
    "#     print(f'Subject {i} Results with CV accuracy of {mean_score} \\n')\n",
    "#     print(scores)\n",
    "#     print(mean_score)\n",
    "#     accuracy_list.append(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC(kernel='linear', C=1, random_state = 101)\n",
    "# subject = master_time[master_time['id'] == 1]\n",
    "# features = subject.drop(['id', 'label'], axis = 1)\n",
    "# scores = cross_val_score(svm, features, subject['label'], \n",
    "#                              cv = 5, scoring = 'accuracy')  \n",
    "# mean_score = scores.mean()\n",
    "# print(f'Subject {i} Results with CV accuracy of {mean_score} \\n')\n",
    "# print(scores)\n",
    "# print(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_relax = master_label_df[master_label_df.label.isin(['math','relax'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['relax', 'math'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_relax.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "math     936\n",
       "relax    934\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_relax['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>indra_time</th>\n",
       "      <th>browser_latency</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>attention_esense</th>\n",
       "      <th>meditation_esense</th>\n",
       "      <th>eeg_power</th>\n",
       "      <th>raw_values</th>\n",
       "      <th>signal_quality</th>\n",
       "      <th>...</th>\n",
       "      <th>low_beta</th>\n",
       "      <th>high_beta</th>\n",
       "      <th>low_gamma</th>\n",
       "      <th>mid+gamma</th>\n",
       "      <th>Session</th>\n",
       "      <th>Seen video before?</th>\n",
       "      <th>Chosen color</th>\n",
       "      <th>Saw icons?</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Wear contacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16409</th>\n",
       "      <td>537</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:32:54.153</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:40.884</td>\n",
       "      <td>51</td>\n",
       "      <td>67</td>\n",
       "      <td>[85497.0, 20547.0, 2723.0, 3270.0, 2522.0, 220...</td>\n",
       "      <td>[17.0, 19.0, 23.0, 25.0, 27.0, 38.0, 51.0, 52....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2522.0</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16410</th>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:32:55.061</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:41.867</td>\n",
       "      <td>38</td>\n",
       "      <td>63</td>\n",
       "      <td>[50036.0, 57439.0, 17659.0, 5816.0, 10021.0, 2...</td>\n",
       "      <td>[44.0, 45.0, 45.0, 51.0, 48.0, 45.0, 48.0, 42....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10021.0</td>\n",
       "      <td>2917.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16411</th>\n",
       "      <td>539</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:32:55.971</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:42.854</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>[155790.0, 43496.0, 14414.0, 8105.0, 8255.0, 7...</td>\n",
       "      <td>[-30.0, -33.0, -27.0, -29.0, -33.0, -33.0, -38...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8255.0</td>\n",
       "      <td>7485.0</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16412</th>\n",
       "      <td>536</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:32:57.179</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:43.839</td>\n",
       "      <td>38</td>\n",
       "      <td>54</td>\n",
       "      <td>[160552.0, 44796.0, 13555.0, 21970.0, 12998.0,...</td>\n",
       "      <td>[57.0, 40.0, 3.0, -10.0, 16.0, 42.0, 65.0, 77....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12998.0</td>\n",
       "      <td>4266.0</td>\n",
       "      <td>2635.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16413</th>\n",
       "      <td>540</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:32:58.089</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:44.858</td>\n",
       "      <td>34</td>\n",
       "      <td>69</td>\n",
       "      <td>[18471.0, 31938.0, 35127.0, 14536.0, 8849.0, 4...</td>\n",
       "      <td>[-1.0, 12.0, 19.0, 16.0, 5.0, 9.0, 32.0, 45.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8849.0</td>\n",
       "      <td>4532.0</td>\n",
       "      <td>2445.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16414</th>\n",
       "      <td>541</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:32:58.999</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:45.861</td>\n",
       "      <td>43</td>\n",
       "      <td>81</td>\n",
       "      <td>[654856.0, 15593.0, 29536.0, 2195.0, 9782.0, 4...</td>\n",
       "      <td>[29.0, 24.0, 20.0, 17.0, 12.0, 18.0, 28.0, 44....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9782.0</td>\n",
       "      <td>4251.0</td>\n",
       "      <td>3421.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16415</th>\n",
       "      <td>543</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:00.211</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:46.830</td>\n",
       "      <td>53</td>\n",
       "      <td>90</td>\n",
       "      <td>[55626.0, 8455.0, 2310.0, 17392.0, 7531.0, 830...</td>\n",
       "      <td>[70.0, 102.0, 81.0, 45.0, 35.0, 40.0, 40.0, 37...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>8307.0</td>\n",
       "      <td>3635.0</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16416</th>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:01.121</td>\n",
       "      <td>13405</td>\n",
       "      <td>2015-05-09 16:32:47.833</td>\n",
       "      <td>56</td>\n",
       "      <td>88</td>\n",
       "      <td>[7146.0, 51617.0, 19665.0, 9369.0, 6162.0, 714...</td>\n",
       "      <td>[7.0, 39.0, 49.0, 23.0, -2.0, -7.0, 16.0, 17.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6162.0</td>\n",
       "      <td>7144.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16417</th>\n",
       "      <td>544</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:02.031</td>\n",
       "      <td>13405</td>\n",
       "      <td>2015-05-09 16:32:48.831</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>[34044.0, 19587.0, 3982.0, 7801.0, 6282.0, 397...</td>\n",
       "      <td>[26.0, 44.0, 60.0, 75.0, 97.0, 102.0, 89.0, 73...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6282.0</td>\n",
       "      <td>3979.0</td>\n",
       "      <td>4541.0</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16418</th>\n",
       "      <td>545</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:02.940</td>\n",
       "      <td>13405</td>\n",
       "      <td>2015-05-09 16:32:49.819</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "      <td>[223971.0, 105078.0, 1440.0, 21766.0, 51282.0,...</td>\n",
       "      <td>[121.0, 140.0, 128.0, 96.0, 102.0, 124.0, 120....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51282.0</td>\n",
       "      <td>10086.0</td>\n",
       "      <td>11648.0</td>\n",
       "      <td>4001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16419</th>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:04.144</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:50.824</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>[1465193.0, 110079.0, 49257.0, 58421.0, 41243....</td>\n",
       "      <td>[241.0, 157.0, 118.0, 120.0, 114.0, 88.0, 57.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41243.0</td>\n",
       "      <td>16919.0</td>\n",
       "      <td>7661.0</td>\n",
       "      <td>9773.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16420</th>\n",
       "      <td>547</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:05.048</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:51.824</td>\n",
       "      <td>37</td>\n",
       "      <td>48</td>\n",
       "      <td>[192748.0, 153987.0, 18137.0, 17325.0, 7891.0,...</td>\n",
       "      <td>[481.0, 506.0, 505.0, 438.0, 374.0, 378.0, 408...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7891.0</td>\n",
       "      <td>3771.0</td>\n",
       "      <td>2071.0</td>\n",
       "      <td>2537.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16421</th>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:05.956</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:52.808</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>[118547.0, 29438.0, 2045.0, 3430.0, 1752.0, 92...</td>\n",
       "      <td>[35.0, 20.0, 26.0, 40.0, 50.0, 71.0, 52.0, 13....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16422</th>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:07.171</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:53.825</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>[634547.0, 16889.0, 3938.0, 4585.0, 3886.0, 21...</td>\n",
       "      <td>[85.0, 88.0, 75.0, 56.0, 38.0, 35.0, 22.0, 13....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3886.0</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>1839.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16423</th>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:08.082</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:54.816</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>[114939.0, 144172.0, 118364.0, 20580.0, 22534....</td>\n",
       "      <td>[58.0, 49.0, 39.0, 36.0, 20.0, 3.0, -2.0, -4.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22534.0</td>\n",
       "      <td>9144.0</td>\n",
       "      <td>3439.0</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16424</th>\n",
       "      <td>551</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:08.992</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:55.804</td>\n",
       "      <td>29</td>\n",
       "      <td>67</td>\n",
       "      <td>[646861.0, 59231.0, 76359.0, 27057.0, 22133.0,...</td>\n",
       "      <td>[48.0, 53.0, 71.0, 77.0, 80.0, 90.0, 89.0, 74....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22133.0</td>\n",
       "      <td>15880.0</td>\n",
       "      <td>4459.0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16425</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:10.204</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:56.803</td>\n",
       "      <td>41</td>\n",
       "      <td>88</td>\n",
       "      <td>[179968.0, 17539.0, 16643.0, 31706.0, 13303.0,...</td>\n",
       "      <td>[109.0, 107.0, 100.0, 91.0, 103.0, 108.0, 102....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13303.0</td>\n",
       "      <td>6961.0</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>2656.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16426</th>\n",
       "      <td>553</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:11.112</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:57.845</td>\n",
       "      <td>26</td>\n",
       "      <td>90</td>\n",
       "      <td>[224428.0, 74399.0, 33591.0, 8670.0, 17483.0, ...</td>\n",
       "      <td>[-267.0, -249.0, -221.0, -197.0, -188.0, -187....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17483.0</td>\n",
       "      <td>2447.0</td>\n",
       "      <td>3131.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16427</th>\n",
       "      <td>554</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:12.021</td>\n",
       "      <td>13404</td>\n",
       "      <td>2015-05-09 16:32:58.807</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "      <td>[604844.0, 45607.0, 12693.0, 4812.0, 10111.0, ...</td>\n",
       "      <td>[54.0, 72.0, 68.0, 52.0, 40.0, 33.0, 32.0, 39....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10111.0</td>\n",
       "      <td>5187.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16428</th>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:12.928</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:32:59.792</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>[545004.0, 48019.0, 5844.0, 5804.0, 4166.0, 33...</td>\n",
       "      <td>[2.0, 6.0, 4.0, -5.0, -11.0, -3.0, 2.0, -3.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4166.0</td>\n",
       "      <td>3328.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16429</th>\n",
       "      <td>556</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:14.139</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:00.791</td>\n",
       "      <td>37</td>\n",
       "      <td>53</td>\n",
       "      <td>[500234.0, 42568.0, 12181.0, 16434.0, 16543.0,...</td>\n",
       "      <td>[85.0, 80.0, 88.0, 113.0, 122.0, 119.0, 128.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16543.0</td>\n",
       "      <td>12541.0</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>3930.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16430</th>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:15.047</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:01.804</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>[396835.0, 313031.0, 12196.0, 13806.0, 6779.0,...</td>\n",
       "      <td>[54.0, 48.0, 56.0, 66.0, 68.0, 58.0, 41.0, 37....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6779.0</td>\n",
       "      <td>9723.0</td>\n",
       "      <td>2633.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16431</th>\n",
       "      <td>558</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:15.954</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:02.778</td>\n",
       "      <td>44</td>\n",
       "      <td>27</td>\n",
       "      <td>[226473.0, 14523.0, 1295.0, 1744.0, 3581.0, 26...</td>\n",
       "      <td>[-68.0, -56.0, -52.0, -54.0, -46.0, -35.0, -20...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>2690.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16432</th>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:17.166</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:03.769</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>[190851.0, 46447.0, 7622.0, 9326.0, 11090.0, 2...</td>\n",
       "      <td>[35.0, 39.0, 56.0, 67.0, 70.0, 57.0, 51.0, 52....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11090.0</td>\n",
       "      <td>20169.0</td>\n",
       "      <td>3870.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16433</th>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:18.073</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:04.778</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>[808539.0, 99887.0, 6214.0, 4678.0, 13998.0, 6...</td>\n",
       "      <td>[168.0, 161.0, 155.0, 149.0, 131.0, 121.0, 132...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13998.0</td>\n",
       "      <td>6691.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16434</th>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:18.981</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:05.778</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "      <td>[61867.0, 50113.0, 15249.0, 23042.0, 6096.0, 1...</td>\n",
       "      <td>[91.0, 100.0, 116.0, 134.0, 131.0, 128.0, 141....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6096.0</td>\n",
       "      <td>15258.0</td>\n",
       "      <td>2528.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16435</th>\n",
       "      <td>562</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:19.889</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:06.771</td>\n",
       "      <td>66</td>\n",
       "      <td>44</td>\n",
       "      <td>[21452.0, 37577.0, 26425.0, 4587.0, 18445.0, 9...</td>\n",
       "      <td>[48.0, 70.0, 86.0, 88.0, 75.0, 81.0, 90.0, 99....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18445.0</td>\n",
       "      <td>9730.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16436</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:21.100</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:07.788</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>[174582.0, 63327.0, 14815.0, 25082.0, 14216.0,...</td>\n",
       "      <td>[17.0, 28.0, 44.0, 50.0, 50.0, 56.0, 59.0, 44....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14216.0</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16437</th>\n",
       "      <td>564</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:22.007</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:08.763</td>\n",
       "      <td>47</td>\n",
       "      <td>66</td>\n",
       "      <td>[132429.0, 24231.0, 3596.0, 6952.0, 2979.0, 24...</td>\n",
       "      <td>[86.0, 96.0, 91.0, 66.0, 51.0, 48.0, 45.0, 65....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16438</th>\n",
       "      <td>565</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:22.916</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:09.764</td>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "      <td>[265376.0, 21289.0, 6300.0, 3168.0, 1250.0, 18...</td>\n",
       "      <td>[22.0, 28.0, 55.0, 50.0, 49.0, 32.0, 41.0, 59....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>3478.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16444</th>\n",
       "      <td>571</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:28.977</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:15.726</td>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "      <td>[6650.0, 22871.0, 45854.0, 191253.0, 15457.0, ...</td>\n",
       "      <td>[108.0, 114.0, 120.0, 123.0, 114.0, 104.0, 96....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15457.0</td>\n",
       "      <td>7563.0</td>\n",
       "      <td>3962.0</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16445</th>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:29.889</td>\n",
       "      <td>13403</td>\n",
       "      <td>2015-05-09 16:33:16.744</td>\n",
       "      <td>50</td>\n",
       "      <td>93</td>\n",
       "      <td>[17269.0, 46755.0, 7453.0, 41606.0, 30618.0, 8...</td>\n",
       "      <td>[73.0, 69.0, 70.0, 87.0, 104.0, 107.0, 109.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30618.0</td>\n",
       "      <td>8895.0</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16446</th>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:31.107</td>\n",
       "      <td>13405</td>\n",
       "      <td>2015-05-09 16:33:17.749</td>\n",
       "      <td>56</td>\n",
       "      <td>80</td>\n",
       "      <td>[22435.0, 22581.0, 7030.0, 22607.0, 19750.0, 8...</td>\n",
       "      <td>[54.0, 60.0, 67.0, 64.0, 57.0, 59.0, 70.0, 73....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19750.0</td>\n",
       "      <td>8554.0</td>\n",
       "      <td>4882.0</td>\n",
       "      <td>3404.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16447</th>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:32.019</td>\n",
       "      <td>13405</td>\n",
       "      <td>2015-05-09 16:33:18.735</td>\n",
       "      <td>41</td>\n",
       "      <td>84</td>\n",
       "      <td>[4641.0, 22297.0, 12585.0, 35891.0, 3410.0, 43...</td>\n",
       "      <td>[36.0, 24.0, 28.0, 43.0, 42.0, 36.0, 21.0, -4....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>4374.0</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16448</th>\n",
       "      <td>575</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:32.923</td>\n",
       "      <td>13405</td>\n",
       "      <td>2015-05-09 16:33:19.716</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>[11888.0, 14622.0, 7172.0, 12690.0, 10048.0, 7...</td>\n",
       "      <td>[53.0, 66.0, 56.0, 55.0, 64.0, 53.0, 43.0, 52....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10048.0</td>\n",
       "      <td>7316.0</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>2741.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16449</th>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:34.128</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:20.735</td>\n",
       "      <td>61</td>\n",
       "      <td>75</td>\n",
       "      <td>[15482.0, 11558.0, 32119.0, 37042.0, 25933.0, ...</td>\n",
       "      <td>[52.0, 65.0, 57.0, 43.0, 40.0, 35.0, 26.0, 18....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25933.0</td>\n",
       "      <td>8644.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16450</th>\n",
       "      <td>577</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:35.037</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:21.711</td>\n",
       "      <td>43</td>\n",
       "      <td>93</td>\n",
       "      <td>[7107.0, 6816.0, 1864.0, 112342.0, 10055.0, 28...</td>\n",
       "      <td>[35.0, 27.0, 20.0, 9.0, 12.0, 21.0, 19.0, 11.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>2803.0</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16451</th>\n",
       "      <td>578</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:35.950</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:22.706</td>\n",
       "      <td>43</td>\n",
       "      <td>91</td>\n",
       "      <td>[20107.0, 72684.0, 25025.0, 113397.0, 28565.0,...</td>\n",
       "      <td>[28.0, 40.0, 53.0, 59.0, 54.0, 44.0, 35.0, 29....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28565.0</td>\n",
       "      <td>14290.0</td>\n",
       "      <td>2894.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16452</th>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:36.857</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:23.707</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>[17637.0, 8693.0, 66763.0, 146565.0, 24592.0, ...</td>\n",
       "      <td>[23.0, 36.0, 36.0, 36.0, 54.0, 76.0, 89.0, 89....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24592.0</td>\n",
       "      <td>6576.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>2203.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16453</th>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:38.069</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:24.714</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>[13641.0, 53578.0, 23605.0, 161039.0, 29399.0,...</td>\n",
       "      <td>[66.0, 58.0, 51.0, 37.0, 22.0, 22.0, 27.0, 28....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29399.0</td>\n",
       "      <td>6569.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16454</th>\n",
       "      <td>581</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:38.981</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:25.706</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>[13230.0, 8127.0, 11132.0, 122631.0, 11565.0, ...</td>\n",
       "      <td>[89.0, 85.0, 77.0, 66.0, 55.0, 59.0, 60.0, 50....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11565.0</td>\n",
       "      <td>4495.0</td>\n",
       "      <td>2669.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16455</th>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:39.886</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:26.743</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "      <td>[3696.0, 36922.0, 27992.0, 222616.0, 16098.0, ...</td>\n",
       "      <td>[-3.0, 19.0, 35.0, 36.0, 26.0, 36.0, 60.0, 85....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16098.0</td>\n",
       "      <td>30599.0</td>\n",
       "      <td>2910.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16456</th>\n",
       "      <td>583</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:40.795</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:27.686</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "      <td>[50288.0, 40566.0, 38773.0, 83377.0, 44965.0, ...</td>\n",
       "      <td>[86.0, 81.0, 76.0, 76.0, 82.0, 73.0, 64.0, 49....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44965.0</td>\n",
       "      <td>26306.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>4133.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16457</th>\n",
       "      <td>584</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:42.005</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:28.689</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>[11510.0, 12157.0, 79163.0, 188047.0, 43863.0,...</td>\n",
       "      <td>[57.0, 29.0, 6.0, -6.0, -7.0, -7.0, -6.0, -2.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43863.0</td>\n",
       "      <td>5092.0</td>\n",
       "      <td>2374.0</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16458</th>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:42.915</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:29.689</td>\n",
       "      <td>37</td>\n",
       "      <td>100</td>\n",
       "      <td>[11462.0, 27788.0, 61575.0, 119062.0, 30606.0,...</td>\n",
       "      <td>[23.0, 48.0, 64.0, 54.0, 36.0, 26.0, 26.0, 27....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30606.0</td>\n",
       "      <td>12093.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16459</th>\n",
       "      <td>586</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:43.823</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:30.691</td>\n",
       "      <td>38</td>\n",
       "      <td>93</td>\n",
       "      <td>[14033.0, 36042.0, 12625.0, 47540.0, 18539.0, ...</td>\n",
       "      <td>[96.0, 76.0, 65.0, 64.0, 68.0, 56.0, 37.0, 23....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18539.0</td>\n",
       "      <td>12509.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16460</th>\n",
       "      <td>587</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:45.035</td>\n",
       "      <td>13402</td>\n",
       "      <td>2015-05-09 16:33:31.695</td>\n",
       "      <td>43</td>\n",
       "      <td>93</td>\n",
       "      <td>[7243.0, 12484.0, 47874.0, 57394.0, 46335.0, 3...</td>\n",
       "      <td>[61.0, 65.0, 59.0, 40.0, 29.0, 28.0, 18.0, 4.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>46335.0</td>\n",
       "      <td>30032.0</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16461</th>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:45.938</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:32.676</td>\n",
       "      <td>56</td>\n",
       "      <td>91</td>\n",
       "      <td>[34056.0, 24142.0, 61051.0, 119314.0, 12628.0,...</td>\n",
       "      <td>[12.0, 16.0, 20.0, 22.0, 22.0, 20.0, 10.0, 9.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12628.0</td>\n",
       "      <td>14679.0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>2666.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16462</th>\n",
       "      <td>589</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:46.846</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:33.679</td>\n",
       "      <td>61</td>\n",
       "      <td>88</td>\n",
       "      <td>[18517.0, 30522.0, 13822.0, 102068.0, 21927.0,...</td>\n",
       "      <td>[2.0, 0.0, -2.0, -5.0, -19.0, -29.0, -25.0, -2...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>21927.0</td>\n",
       "      <td>12384.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16463</th>\n",
       "      <td>590</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:48.059</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:34.696</td>\n",
       "      <td>53</td>\n",
       "      <td>94</td>\n",
       "      <td>[17688.0, 20602.0, 26737.0, 80210.0, 30690.0, ...</td>\n",
       "      <td>[48.0, 48.0, 43.0, 35.0, 19.0, 10.0, 16.0, 19....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30690.0</td>\n",
       "      <td>7936.0</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>1318.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16464</th>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:48.970</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:35.671</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>[20148.0, 7016.0, 23182.0, 19044.0, 19904.0, 1...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 12.0, 27.0, 36.0, 33.0, 34.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19904.0</td>\n",
       "      <td>10415.0</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16465</th>\n",
       "      <td>592</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:49.879</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:36.653</td>\n",
       "      <td>48</td>\n",
       "      <td>94</td>\n",
       "      <td>[2890.0, 10281.0, 43907.0, 64111.0, 11092.0, 6...</td>\n",
       "      <td>[3.0, -2.0, -20.0, -22.0, -7.0, 2.0, -5.0, -4....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11092.0</td>\n",
       "      <td>6288.0</td>\n",
       "      <td>2173.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16466</th>\n",
       "      <td>593</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:50.792</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:37.655</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>[3530.0, 7091.0, 19734.0, 80265.0, 10657.0, 12...</td>\n",
       "      <td>[123.0, 139.0, 147.0, 137.0, 128.0, 118.0, 113...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10657.0</td>\n",
       "      <td>12959.0</td>\n",
       "      <td>3318.0</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16467</th>\n",
       "      <td>594</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:52.005</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:38.642</td>\n",
       "      <td>53</td>\n",
       "      <td>96</td>\n",
       "      <td>[143208.0, 49443.0, 30992.0, 72803.0, 26976.0,...</td>\n",
       "      <td>[24.0, 43.0, 54.0, 58.0, 69.0, 73.0, 75.0, 83....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26976.0</td>\n",
       "      <td>11386.0</td>\n",
       "      <td>3425.0</td>\n",
       "      <td>3422.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16468</th>\n",
       "      <td>595</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:52.916</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:39.643</td>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "      <td>[6843.0, 5721.0, 17771.0, 96605.0, 27594.0, 15...</td>\n",
       "      <td>[-2.0, 10.0, 24.0, 25.0, 16.0, 21.0, 36.0, 42....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27594.0</td>\n",
       "      <td>15218.0</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16469</th>\n",
       "      <td>596</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:53.831</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:40.694</td>\n",
       "      <td>44</td>\n",
       "      <td>100</td>\n",
       "      <td>[11051.0, 46277.0, 129555.0, 102689.0, 5928.0,...</td>\n",
       "      <td>[58.0, 61.0, 64.0, 56.0, 59.0, 69.0, 60.0, 44....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5928.0</td>\n",
       "      <td>10895.0</td>\n",
       "      <td>5809.0</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16470</th>\n",
       "      <td>598</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:54.742</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:41.635</td>\n",
       "      <td>47</td>\n",
       "      <td>91</td>\n",
       "      <td>[33374.0, 11831.0, 3696.0, 18759.0, 8544.0, 51...</td>\n",
       "      <td>[75.0, 72.0, 72.0, 65.0, 36.0, 12.0, 17.0, 27....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8544.0</td>\n",
       "      <td>5122.0</td>\n",
       "      <td>4078.0</td>\n",
       "      <td>3548.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16471</th>\n",
       "      <td>599</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:55.956</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:42.649</td>\n",
       "      <td>47</td>\n",
       "      <td>81</td>\n",
       "      <td>[263169.0, 31802.0, 7123.0, 7273.0, 6518.0, 34...</td>\n",
       "      <td>[41.0, 66.0, 82.0, 76.0, 58.0, 48.0, 53.0, 64....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6518.0</td>\n",
       "      <td>3476.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>3103.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16472</th>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:56.866</td>\n",
       "      <td>13401</td>\n",
       "      <td>2015-05-09 16:33:43.638</td>\n",
       "      <td>43</td>\n",
       "      <td>81</td>\n",
       "      <td>[114362.0, 16018.0, 25348.0, 38073.0, 7682.0, ...</td>\n",
       "      <td>[35.0, 40.0, 52.0, 54.0, 40.0, 26.0, 23.0, 19....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7682.0</td>\n",
       "      <td>6785.0</td>\n",
       "      <td>2074.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16473</th>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-09 23:33:57.774</td>\n",
       "      <td>13400</td>\n",
       "      <td>2015-05-09 16:33:44.623</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>[22817.0, 30823.0, 1176.0, 1976.0, 1952.0, 206...</td>\n",
       "      <td>[67.0, 73.0, 80.0, 72.0, 60.0, 53.0, 49.0, 50....</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  id              indra_time browser_latency  \\\n",
       "16409         537   1 2015-05-09 23:32:54.153           13404   \n",
       "16410         538   1 2015-05-09 23:32:55.061           13404   \n",
       "16411         539   1 2015-05-09 23:32:55.971           13404   \n",
       "16412         536   1 2015-05-09 23:32:57.179           13404   \n",
       "16413         540   1 2015-05-09 23:32:58.089           13404   \n",
       "16414         541   1 2015-05-09 23:32:58.999           13404   \n",
       "16415         543   1 2015-05-09 23:33:00.211           13404   \n",
       "16416         542   1 2015-05-09 23:33:01.121           13405   \n",
       "16417         544   1 2015-05-09 23:33:02.031           13405   \n",
       "16418         545   1 2015-05-09 23:33:02.940           13405   \n",
       "16419         546   1 2015-05-09 23:33:04.144           13404   \n",
       "16420         547   1 2015-05-09 23:33:05.048           13404   \n",
       "16421         548   1 2015-05-09 23:33:05.956           13404   \n",
       "16422         549   1 2015-05-09 23:33:07.171           13404   \n",
       "16423         550   1 2015-05-09 23:33:08.082           13404   \n",
       "16424         551   1 2015-05-09 23:33:08.992           13404   \n",
       "16425         552   1 2015-05-09 23:33:10.204           13404   \n",
       "16426         553   1 2015-05-09 23:33:11.112           13404   \n",
       "16427         554   1 2015-05-09 23:33:12.021           13404   \n",
       "16428         555   1 2015-05-09 23:33:12.928           13403   \n",
       "16429         556   1 2015-05-09 23:33:14.139           13403   \n",
       "16430         557   1 2015-05-09 23:33:15.047           13403   \n",
       "16431         558   1 2015-05-09 23:33:15.954           13403   \n",
       "16432         559   1 2015-05-09 23:33:17.166           13403   \n",
       "16433         560   1 2015-05-09 23:33:18.073           13403   \n",
       "16434         561   1 2015-05-09 23:33:18.981           13403   \n",
       "16435         562   1 2015-05-09 23:33:19.889           13403   \n",
       "16436         563   1 2015-05-09 23:33:21.100           13403   \n",
       "16437         564   1 2015-05-09 23:33:22.007           13403   \n",
       "16438         565   1 2015-05-09 23:33:22.916           13403   \n",
       "16444         571   1 2015-05-09 23:33:28.977           13403   \n",
       "16445         572   1 2015-05-09 23:33:29.889           13403   \n",
       "16446         573   1 2015-05-09 23:33:31.107           13405   \n",
       "16447         574   1 2015-05-09 23:33:32.019           13405   \n",
       "16448         575   1 2015-05-09 23:33:32.923           13405   \n",
       "16449         576   1 2015-05-09 23:33:34.128           13402   \n",
       "16450         577   1 2015-05-09 23:33:35.037           13402   \n",
       "16451         578   1 2015-05-09 23:33:35.950           13402   \n",
       "16452         579   1 2015-05-09 23:33:36.857           13402   \n",
       "16453         580   1 2015-05-09 23:33:38.069           13402   \n",
       "16454         581   1 2015-05-09 23:33:38.981           13402   \n",
       "16455         582   1 2015-05-09 23:33:39.886           13402   \n",
       "16456         583   1 2015-05-09 23:33:40.795           13402   \n",
       "16457         584   1 2015-05-09 23:33:42.005           13402   \n",
       "16458         585   1 2015-05-09 23:33:42.915           13402   \n",
       "16459         586   1 2015-05-09 23:33:43.823           13402   \n",
       "16460         587   1 2015-05-09 23:33:45.035           13402   \n",
       "16461         588   1 2015-05-09 23:33:45.938           13401   \n",
       "16462         589   1 2015-05-09 23:33:46.846           13401   \n",
       "16463         590   1 2015-05-09 23:33:48.059           13401   \n",
       "16464         591   1 2015-05-09 23:33:48.970           13401   \n",
       "16465         592   1 2015-05-09 23:33:49.879           13401   \n",
       "16466         593   1 2015-05-09 23:33:50.792           13401   \n",
       "16467         594   1 2015-05-09 23:33:52.005           13401   \n",
       "16468         595   1 2015-05-09 23:33:52.916           13401   \n",
       "16469         596   1 2015-05-09 23:33:53.831           13401   \n",
       "16470         598   1 2015-05-09 23:33:54.742           13401   \n",
       "16471         599   1 2015-05-09 23:33:55.956           13401   \n",
       "16472         600   1 2015-05-09 23:33:56.866           13401   \n",
       "16473         601   1 2015-05-09 23:33:57.774           13400   \n",
       "\n",
       "                 reading_time  attention_esense  meditation_esense  \\\n",
       "16409 2015-05-09 16:32:40.884                51                 67   \n",
       "16410 2015-05-09 16:32:41.867                38                 63   \n",
       "16411 2015-05-09 16:32:42.854                38                 57   \n",
       "16412 2015-05-09 16:32:43.839                38                 54   \n",
       "16413 2015-05-09 16:32:44.858                34                 69   \n",
       "16414 2015-05-09 16:32:45.861                43                 81   \n",
       "16415 2015-05-09 16:32:46.830                53                 90   \n",
       "16416 2015-05-09 16:32:47.833                56                 88   \n",
       "16417 2015-05-09 16:32:48.831                64                 78   \n",
       "16418 2015-05-09 16:32:49.819                61                 57   \n",
       "16419 2015-05-09 16:32:50.824                50                 56   \n",
       "16420 2015-05-09 16:32:51.824                37                 48   \n",
       "16421 2015-05-09 16:32:52.808                21                 40   \n",
       "16422 2015-05-09 16:32:53.825                23                 50   \n",
       "16423 2015-05-09 16:32:54.816                14                 53   \n",
       "16424 2015-05-09 16:32:55.804                29                 67   \n",
       "16425 2015-05-09 16:32:56.803                41                 88   \n",
       "16426 2015-05-09 16:32:57.845                26                 90   \n",
       "16427 2015-05-09 16:32:58.807                37                 80   \n",
       "16428 2015-05-09 16:32:59.792                30                 63   \n",
       "16429 2015-05-09 16:33:00.791                37                 53   \n",
       "16430 2015-05-09 16:33:01.804                40                 35   \n",
       "16431 2015-05-09 16:33:02.778                44                 27   \n",
       "16432 2015-05-09 16:33:03.769                60                 27   \n",
       "16433 2015-05-09 16:33:04.778                51                 14   \n",
       "16434 2015-05-09 16:33:05.778                67                 34   \n",
       "16435 2015-05-09 16:33:06.771                66                 44   \n",
       "16436 2015-05-09 16:33:07.788                47                 53   \n",
       "16437 2015-05-09 16:33:08.763                47                 66   \n",
       "16438 2015-05-09 16:33:09.764                37                 63   \n",
       "16444 2015-05-09 16:33:15.726                48                100   \n",
       "16445 2015-05-09 16:33:16.744                50                 93   \n",
       "16446 2015-05-09 16:33:17.749                56                 80   \n",
       "16447 2015-05-09 16:33:18.735                41                 84   \n",
       "16448 2015-05-09 16:33:19.716                60                 66   \n",
       "16449 2015-05-09 16:33:20.735                61                 75   \n",
       "16450 2015-05-09 16:33:21.711                43                 93   \n",
       "16451 2015-05-09 16:33:22.706                43                 91   \n",
       "16452 2015-05-09 16:33:23.707                24                100   \n",
       "16453 2015-05-09 16:33:24.714                11                100   \n",
       "16454 2015-05-09 16:33:25.706                14                100   \n",
       "16455 2015-05-09 16:33:26.743                17                100   \n",
       "16456 2015-05-09 16:33:27.686                35                100   \n",
       "16457 2015-05-09 16:33:28.689                29                100   \n",
       "16458 2015-05-09 16:33:29.689                37                100   \n",
       "16459 2015-05-09 16:33:30.691                38                 93   \n",
       "16460 2015-05-09 16:33:31.695                43                 93   \n",
       "16461 2015-05-09 16:33:32.676                56                 91   \n",
       "16462 2015-05-09 16:33:33.679                61                 88   \n",
       "16463 2015-05-09 16:33:34.696                53                 94   \n",
       "16464 2015-05-09 16:33:35.671                51                 94   \n",
       "16465 2015-05-09 16:33:36.653                48                 94   \n",
       "16466 2015-05-09 16:33:37.655                51                100   \n",
       "16467 2015-05-09 16:33:38.642                53                 96   \n",
       "16468 2015-05-09 16:33:39.643                48                100   \n",
       "16469 2015-05-09 16:33:40.694                44                100   \n",
       "16470 2015-05-09 16:33:41.635                47                 91   \n",
       "16471 2015-05-09 16:33:42.649                47                 81   \n",
       "16472 2015-05-09 16:33:43.638                43                 81   \n",
       "16473 2015-05-09 16:33:44.623                48                 51   \n",
       "\n",
       "                                               eeg_power  \\\n",
       "16409  [85497.0, 20547.0, 2723.0, 3270.0, 2522.0, 220...   \n",
       "16410  [50036.0, 57439.0, 17659.0, 5816.0, 10021.0, 2...   \n",
       "16411  [155790.0, 43496.0, 14414.0, 8105.0, 8255.0, 7...   \n",
       "16412  [160552.0, 44796.0, 13555.0, 21970.0, 12998.0,...   \n",
       "16413  [18471.0, 31938.0, 35127.0, 14536.0, 8849.0, 4...   \n",
       "16414  [654856.0, 15593.0, 29536.0, 2195.0, 9782.0, 4...   \n",
       "16415  [55626.0, 8455.0, 2310.0, 17392.0, 7531.0, 830...   \n",
       "16416  [7146.0, 51617.0, 19665.0, 9369.0, 6162.0, 714...   \n",
       "16417  [34044.0, 19587.0, 3982.0, 7801.0, 6282.0, 397...   \n",
       "16418  [223971.0, 105078.0, 1440.0, 21766.0, 51282.0,...   \n",
       "16419  [1465193.0, 110079.0, 49257.0, 58421.0, 41243....   \n",
       "16420  [192748.0, 153987.0, 18137.0, 17325.0, 7891.0,...   \n",
       "16421  [118547.0, 29438.0, 2045.0, 3430.0, 1752.0, 92...   \n",
       "16422  [634547.0, 16889.0, 3938.0, 4585.0, 3886.0, 21...   \n",
       "16423  [114939.0, 144172.0, 118364.0, 20580.0, 22534....   \n",
       "16424  [646861.0, 59231.0, 76359.0, 27057.0, 22133.0,...   \n",
       "16425  [179968.0, 17539.0, 16643.0, 31706.0, 13303.0,...   \n",
       "16426  [224428.0, 74399.0, 33591.0, 8670.0, 17483.0, ...   \n",
       "16427  [604844.0, 45607.0, 12693.0, 4812.0, 10111.0, ...   \n",
       "16428  [545004.0, 48019.0, 5844.0, 5804.0, 4166.0, 33...   \n",
       "16429  [500234.0, 42568.0, 12181.0, 16434.0, 16543.0,...   \n",
       "16430  [396835.0, 313031.0, 12196.0, 13806.0, 6779.0,...   \n",
       "16431  [226473.0, 14523.0, 1295.0, 1744.0, 3581.0, 26...   \n",
       "16432  [190851.0, 46447.0, 7622.0, 9326.0, 11090.0, 2...   \n",
       "16433  [808539.0, 99887.0, 6214.0, 4678.0, 13998.0, 6...   \n",
       "16434  [61867.0, 50113.0, 15249.0, 23042.0, 6096.0, 1...   \n",
       "16435  [21452.0, 37577.0, 26425.0, 4587.0, 18445.0, 9...   \n",
       "16436  [174582.0, 63327.0, 14815.0, 25082.0, 14216.0,...   \n",
       "16437  [132429.0, 24231.0, 3596.0, 6952.0, 2979.0, 24...   \n",
       "16438  [265376.0, 21289.0, 6300.0, 3168.0, 1250.0, 18...   \n",
       "16444  [6650.0, 22871.0, 45854.0, 191253.0, 15457.0, ...   \n",
       "16445  [17269.0, 46755.0, 7453.0, 41606.0, 30618.0, 8...   \n",
       "16446  [22435.0, 22581.0, 7030.0, 22607.0, 19750.0, 8...   \n",
       "16447  [4641.0, 22297.0, 12585.0, 35891.0, 3410.0, 43...   \n",
       "16448  [11888.0, 14622.0, 7172.0, 12690.0, 10048.0, 7...   \n",
       "16449  [15482.0, 11558.0, 32119.0, 37042.0, 25933.0, ...   \n",
       "16450  [7107.0, 6816.0, 1864.0, 112342.0, 10055.0, 28...   \n",
       "16451  [20107.0, 72684.0, 25025.0, 113397.0, 28565.0,...   \n",
       "16452  [17637.0, 8693.0, 66763.0, 146565.0, 24592.0, ...   \n",
       "16453  [13641.0, 53578.0, 23605.0, 161039.0, 29399.0,...   \n",
       "16454  [13230.0, 8127.0, 11132.0, 122631.0, 11565.0, ...   \n",
       "16455  [3696.0, 36922.0, 27992.0, 222616.0, 16098.0, ...   \n",
       "16456  [50288.0, 40566.0, 38773.0, 83377.0, 44965.0, ...   \n",
       "16457  [11510.0, 12157.0, 79163.0, 188047.0, 43863.0,...   \n",
       "16458  [11462.0, 27788.0, 61575.0, 119062.0, 30606.0,...   \n",
       "16459  [14033.0, 36042.0, 12625.0, 47540.0, 18539.0, ...   \n",
       "16460  [7243.0, 12484.0, 47874.0, 57394.0, 46335.0, 3...   \n",
       "16461  [34056.0, 24142.0, 61051.0, 119314.0, 12628.0,...   \n",
       "16462  [18517.0, 30522.0, 13822.0, 102068.0, 21927.0,...   \n",
       "16463  [17688.0, 20602.0, 26737.0, 80210.0, 30690.0, ...   \n",
       "16464  [20148.0, 7016.0, 23182.0, 19044.0, 19904.0, 1...   \n",
       "16465  [2890.0, 10281.0, 43907.0, 64111.0, 11092.0, 6...   \n",
       "16466  [3530.0, 7091.0, 19734.0, 80265.0, 10657.0, 12...   \n",
       "16467  [143208.0, 49443.0, 30992.0, 72803.0, 26976.0,...   \n",
       "16468  [6843.0, 5721.0, 17771.0, 96605.0, 27594.0, 15...   \n",
       "16469  [11051.0, 46277.0, 129555.0, 102689.0, 5928.0,...   \n",
       "16470  [33374.0, 11831.0, 3696.0, 18759.0, 8544.0, 51...   \n",
       "16471  [263169.0, 31802.0, 7123.0, 7273.0, 6518.0, 34...   \n",
       "16472  [114362.0, 16018.0, 25348.0, 38073.0, 7682.0, ...   \n",
       "16473  [22817.0, 30823.0, 1176.0, 1976.0, 1952.0, 206...   \n",
       "\n",
       "                                              raw_values  signal_quality  ...  \\\n",
       "16409  [17.0, 19.0, 23.0, 25.0, 27.0, 38.0, 51.0, 52....               0  ...   \n",
       "16410  [44.0, 45.0, 45.0, 51.0, 48.0, 45.0, 48.0, 42....               0  ...   \n",
       "16411  [-30.0, -33.0, -27.0, -29.0, -33.0, -33.0, -38...               0  ...   \n",
       "16412  [57.0, 40.0, 3.0, -10.0, 16.0, 42.0, 65.0, 77....               0  ...   \n",
       "16413  [-1.0, 12.0, 19.0, 16.0, 5.0, 9.0, 32.0, 45.0,...               0  ...   \n",
       "16414  [29.0, 24.0, 20.0, 17.0, 12.0, 18.0, 28.0, 44....               0  ...   \n",
       "16415  [70.0, 102.0, 81.0, 45.0, 35.0, 40.0, 40.0, 37...               0  ...   \n",
       "16416  [7.0, 39.0, 49.0, 23.0, -2.0, -7.0, 16.0, 17.0...               0  ...   \n",
       "16417  [26.0, 44.0, 60.0, 75.0, 97.0, 102.0, 89.0, 73...               0  ...   \n",
       "16418  [121.0, 140.0, 128.0, 96.0, 102.0, 124.0, 120....               0  ...   \n",
       "16419  [241.0, 157.0, 118.0, 120.0, 114.0, 88.0, 57.0...               0  ...   \n",
       "16420  [481.0, 506.0, 505.0, 438.0, 374.0, 378.0, 408...               0  ...   \n",
       "16421  [35.0, 20.0, 26.0, 40.0, 50.0, 71.0, 52.0, 13....               0  ...   \n",
       "16422  [85.0, 88.0, 75.0, 56.0, 38.0, 35.0, 22.0, 13....               0  ...   \n",
       "16423  [58.0, 49.0, 39.0, 36.0, 20.0, 3.0, -2.0, -4.0...               0  ...   \n",
       "16424  [48.0, 53.0, 71.0, 77.0, 80.0, 90.0, 89.0, 74....               0  ...   \n",
       "16425  [109.0, 107.0, 100.0, 91.0, 103.0, 108.0, 102....               0  ...   \n",
       "16426  [-267.0, -249.0, -221.0, -197.0, -188.0, -187....               0  ...   \n",
       "16427  [54.0, 72.0, 68.0, 52.0, 40.0, 33.0, 32.0, 39....               0  ...   \n",
       "16428  [2.0, 6.0, 4.0, -5.0, -11.0, -3.0, 2.0, -3.0, ...               0  ...   \n",
       "16429  [85.0, 80.0, 88.0, 113.0, 122.0, 119.0, 128.0,...               0  ...   \n",
       "16430  [54.0, 48.0, 56.0, 66.0, 68.0, 58.0, 41.0, 37....               0  ...   \n",
       "16431  [-68.0, -56.0, -52.0, -54.0, -46.0, -35.0, -20...               0  ...   \n",
       "16432  [35.0, 39.0, 56.0, 67.0, 70.0, 57.0, 51.0, 52....               0  ...   \n",
       "16433  [168.0, 161.0, 155.0, 149.0, 131.0, 121.0, 132...               0  ...   \n",
       "16434  [91.0, 100.0, 116.0, 134.0, 131.0, 128.0, 141....               0  ...   \n",
       "16435  [48.0, 70.0, 86.0, 88.0, 75.0, 81.0, 90.0, 99....               0  ...   \n",
       "16436  [17.0, 28.0, 44.0, 50.0, 50.0, 56.0, 59.0, 44....               0  ...   \n",
       "16437  [86.0, 96.0, 91.0, 66.0, 51.0, 48.0, 45.0, 65....               0  ...   \n",
       "16438  [22.0, 28.0, 55.0, 50.0, 49.0, 32.0, 41.0, 59....               0  ...   \n",
       "16444  [108.0, 114.0, 120.0, 123.0, 114.0, 104.0, 96....               0  ...   \n",
       "16445  [73.0, 69.0, 70.0, 87.0, 104.0, 107.0, 109.0, ...               0  ...   \n",
       "16446  [54.0, 60.0, 67.0, 64.0, 57.0, 59.0, 70.0, 73....               0  ...   \n",
       "16447  [36.0, 24.0, 28.0, 43.0, 42.0, 36.0, 21.0, -4....               0  ...   \n",
       "16448  [53.0, 66.0, 56.0, 55.0, 64.0, 53.0, 43.0, 52....               0  ...   \n",
       "16449  [52.0, 65.0, 57.0, 43.0, 40.0, 35.0, 26.0, 18....               0  ...   \n",
       "16450  [35.0, 27.0, 20.0, 9.0, 12.0, 21.0, 19.0, 11.0...               0  ...   \n",
       "16451  [28.0, 40.0, 53.0, 59.0, 54.0, 44.0, 35.0, 29....               0  ...   \n",
       "16452  [23.0, 36.0, 36.0, 36.0, 54.0, 76.0, 89.0, 89....               0  ...   \n",
       "16453  [66.0, 58.0, 51.0, 37.0, 22.0, 22.0, 27.0, 28....               0  ...   \n",
       "16454  [89.0, 85.0, 77.0, 66.0, 55.0, 59.0, 60.0, 50....               0  ...   \n",
       "16455  [-3.0, 19.0, 35.0, 36.0, 26.0, 36.0, 60.0, 85....               0  ...   \n",
       "16456  [86.0, 81.0, 76.0, 76.0, 82.0, 73.0, 64.0, 49....               0  ...   \n",
       "16457  [57.0, 29.0, 6.0, -6.0, -7.0, -7.0, -6.0, -2.0...               0  ...   \n",
       "16458  [23.0, 48.0, 64.0, 54.0, 36.0, 26.0, 26.0, 27....               0  ...   \n",
       "16459  [96.0, 76.0, 65.0, 64.0, 68.0, 56.0, 37.0, 23....               0  ...   \n",
       "16460  [61.0, 65.0, 59.0, 40.0, 29.0, 28.0, 18.0, 4.0...               0  ...   \n",
       "16461  [12.0, 16.0, 20.0, 22.0, 22.0, 20.0, 10.0, 9.0...               0  ...   \n",
       "16462  [2.0, 0.0, -2.0, -5.0, -19.0, -29.0, -25.0, -2...               0  ...   \n",
       "16463  [48.0, 48.0, 43.0, 35.0, 19.0, 10.0, 16.0, 19....               0  ...   \n",
       "16464  [1.0, 1.0, 1.0, 12.0, 27.0, 36.0, 33.0, 34.0, ...               0  ...   \n",
       "16465  [3.0, -2.0, -20.0, -22.0, -7.0, 2.0, -5.0, -4....               0  ...   \n",
       "16466  [123.0, 139.0, 147.0, 137.0, 128.0, 118.0, 113...               0  ...   \n",
       "16467  [24.0, 43.0, 54.0, 58.0, 69.0, 73.0, 75.0, 83....               0  ...   \n",
       "16468  [-2.0, 10.0, 24.0, 25.0, 16.0, 21.0, 36.0, 42....               0  ...   \n",
       "16469  [58.0, 61.0, 64.0, 56.0, 59.0, 69.0, 60.0, 44....               0  ...   \n",
       "16470  [75.0, 72.0, 72.0, 65.0, 36.0, 12.0, 17.0, 27....               0  ...   \n",
       "16471  [41.0, 66.0, 82.0, 76.0, 58.0, 48.0, 53.0, 64....               0  ...   \n",
       "16472  [35.0, 40.0, 52.0, 54.0, 40.0, 26.0, 23.0, 19....               0  ...   \n",
       "16473  [67.0, 73.0, 80.0, 72.0, 60.0, 53.0, 49.0, 50....               0  ...   \n",
       "\n",
       "      low_beta high_beta low_gamma  mid+gamma  Session  Seen video before?  \\\n",
       "16409   2522.0    2209.0     449.0      393.0        1                   n   \n",
       "16410  10021.0    2917.0    1030.0     1264.0        1                   n   \n",
       "16411   8255.0    7485.0    2610.0     4343.0        1                   n   \n",
       "16412  12998.0    4266.0    2635.0     1820.0        1                   n   \n",
       "16413   8849.0    4532.0    2445.0      670.0        1                   n   \n",
       "16414   9782.0    4251.0    3421.0     2631.0        1                   n   \n",
       "16415   7531.0    8307.0    3635.0     1812.0        1                   n   \n",
       "16416   6162.0    7144.0    1961.0     1853.0        1                   n   \n",
       "16417   6282.0    3979.0    4541.0     1298.0        1                   n   \n",
       "16418  51282.0   10086.0   11648.0     4001.0        1                   n   \n",
       "16419  41243.0   16919.0    7661.0     9773.0        1                   n   \n",
       "16420   7891.0    3771.0    2071.0     2537.0        1                   n   \n",
       "16421   1752.0     927.0     959.0      918.0        1                   n   \n",
       "16422   3886.0    2120.0    1839.0      963.0        1                   n   \n",
       "16423  22534.0    9144.0    3439.0     3032.0        1                   n   \n",
       "16424  22133.0   15880.0    4459.0     2385.0        1                   n   \n",
       "16425  13303.0    6961.0    3359.0     2656.0        1                   n   \n",
       "16426  17483.0    2447.0    3131.0      932.0        1                   n   \n",
       "16427  10111.0    5187.0    1286.0      756.0        1                   n   \n",
       "16428   4166.0    3328.0     456.0      626.0        1                   n   \n",
       "16429  16543.0   12541.0    2636.0     3930.0        1                   n   \n",
       "16430   6779.0    9723.0    2633.0     1156.0        1                   n   \n",
       "16431   3581.0    2690.0     523.0      576.0        1                   n   \n",
       "16432  11090.0   20169.0    3870.0     1336.0        1                   n   \n",
       "16433  13998.0    6691.0    1437.0     1956.0        1                   n   \n",
       "16434   6096.0   15258.0    2528.0      908.0        1                   n   \n",
       "16435  18445.0    9730.0    1633.0     1410.0        1                   n   \n",
       "16436  14216.0    3306.0    1992.0     1136.0        1                   n   \n",
       "16437   2979.0    2487.0    1446.0     1649.0        1                   n   \n",
       "16438   1250.0    1834.0    3478.0     1605.0        1                   n   \n",
       "16444  15457.0    7563.0    3962.0     2285.0        1                   n   \n",
       "16445  30618.0    8895.0    2843.0     1990.0        1                   n   \n",
       "16446  19750.0    8554.0    4882.0     3404.0        1                   n   \n",
       "16447   3410.0    4374.0    2610.0     1504.0        1                   n   \n",
       "16448  10048.0    7316.0    2437.0     2741.0        1                   n   \n",
       "16449  25933.0    8644.0    1410.0      860.0        1                   n   \n",
       "16450  10055.0    2803.0    2623.0     1126.0        1                   n   \n",
       "16451  28565.0   14290.0    2894.0     1205.0        1                   n   \n",
       "16452  24592.0    6576.0    2300.0     2203.0        1                   n   \n",
       "16453  29399.0    6569.0    3235.0     1564.0        1                   n   \n",
       "16454  11565.0    4495.0    2669.0      641.0        1                   n   \n",
       "16455  16098.0   30599.0    2910.0     1014.0        1                   n   \n",
       "16456  44965.0   26306.0    1104.0     4133.0        1                   n   \n",
       "16457  43863.0    5092.0    2374.0     2038.0        1                   n   \n",
       "16458  30606.0   12093.0    2294.0     1901.0        1                   n   \n",
       "16459  18539.0   12509.0    2390.0     1106.0        1                   n   \n",
       "16460  46335.0   30032.0    1706.0     1913.0        1                   n   \n",
       "16461  12628.0   14679.0    1345.0     2666.0        1                   n   \n",
       "16462  21927.0   12384.0    2236.0     1417.0        1                   n   \n",
       "16463  30690.0    7936.0    1684.0     1318.0        1                   n   \n",
       "16464  19904.0   10415.0    1930.0     1240.0        1                   n   \n",
       "16465  11092.0    6288.0    2173.0      825.0        1                   n   \n",
       "16466  10657.0   12959.0    3318.0     1259.0        1                   n   \n",
       "16467  26976.0   11386.0    3425.0     3422.0        1                   n   \n",
       "16468  27594.0   15218.0    1523.0      997.0        1                   n   \n",
       "16469   5928.0   10895.0    5809.0     1634.0        1                   n   \n",
       "16470   8544.0    5122.0    4078.0     3548.0        1                   n   \n",
       "16471   6518.0    3476.0    1490.0     3103.0        1                   n   \n",
       "16472   7682.0    6785.0    2074.0      936.0        1                   n   \n",
       "16473   1952.0    2064.0     500.0      371.0        1                   n   \n",
       "\n",
       "       Chosen color  Saw icons?  Gender  Wear contacts  \n",
       "16409             b           n       f              n  \n",
       "16410             b           n       f              n  \n",
       "16411             b           n       f              n  \n",
       "16412             b           n       f              n  \n",
       "16413             b           n       f              n  \n",
       "16414             b           n       f              n  \n",
       "16415             b           n       f              n  \n",
       "16416             b           n       f              n  \n",
       "16417             b           n       f              n  \n",
       "16418             b           n       f              n  \n",
       "16419             b           n       f              n  \n",
       "16420             b           n       f              n  \n",
       "16421             b           n       f              n  \n",
       "16422             b           n       f              n  \n",
       "16423             b           n       f              n  \n",
       "16424             b           n       f              n  \n",
       "16425             b           n       f              n  \n",
       "16426             b           n       f              n  \n",
       "16427             b           n       f              n  \n",
       "16428             b           n       f              n  \n",
       "16429             b           n       f              n  \n",
       "16430             b           n       f              n  \n",
       "16431             b           n       f              n  \n",
       "16432             b           n       f              n  \n",
       "16433             b           n       f              n  \n",
       "16434             b           n       f              n  \n",
       "16435             b           n       f              n  \n",
       "16436             b           n       f              n  \n",
       "16437             b           n       f              n  \n",
       "16438             b           n       f              n  \n",
       "16444             b           n       f              n  \n",
       "16445             b           n       f              n  \n",
       "16446             b           n       f              n  \n",
       "16447             b           n       f              n  \n",
       "16448             b           n       f              n  \n",
       "16449             b           n       f              n  \n",
       "16450             b           n       f              n  \n",
       "16451             b           n       f              n  \n",
       "16452             b           n       f              n  \n",
       "16453             b           n       f              n  \n",
       "16454             b           n       f              n  \n",
       "16455             b           n       f              n  \n",
       "16456             b           n       f              n  \n",
       "16457             b           n       f              n  \n",
       "16458             b           n       f              n  \n",
       "16459             b           n       f              n  \n",
       "16460             b           n       f              n  \n",
       "16461             b           n       f              n  \n",
       "16462             b           n       f              n  \n",
       "16463             b           n       f              n  \n",
       "16464             b           n       f              n  \n",
       "16465             b           n       f              n  \n",
       "16466             b           n       f              n  \n",
       "16467             b           n       f              n  \n",
       "16468             b           n       f              n  \n",
       "16469             b           n       f              n  \n",
       "16470             b           n       f              n  \n",
       "16471             b           n       f              n  \n",
       "16472             b           n       f              n  \n",
       "16473             b           n       f              n  \n",
       "\n",
       "[60 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = math_relax[math_relax['id'] == 1]\n",
    "subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = math_relax.drop(['Unnamed: 0', 'id', 'indra_time','reading_time', 'browser_latency', 'eeg_power', 'raw_values',\n",
    "       'signal_quality', 'createdAt', 'updatedAt', 'Session', 'Seen video before?', 'Chosen color',\n",
    "       'Saw icons?', 'Gender', 'Wear contacts','label'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,math_relax['label'], test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        math       0.55      0.70      0.62       277\n",
      "       relax       0.60      0.44      0.51       284\n",
      "\n",
      "    accuracy                           0.57       561\n",
      "   macro avg       0.58      0.57      0.56       561\n",
      "weighted avg       0.58      0.57      0.56       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 56.86%\n",
      " Precision: 57.56%\n",
      "    Recall: 56.86%\n",
      "  F1 score: 56.13%\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy/precision/recall/f1\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = (accuracy_score(y_test, pred)).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Accuracy',accuracy))\n",
    "# precision tp / (tp + fp)\n",
    "precision = (precision_score(y_test, pred, average = 'weighted')).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Precision',precision))\n",
    "# recall: tp / (tp + fn)\n",
    "recall = (recall_score(y_test, pred, average = 'weighted')).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Recall',recall))\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = (f1_score(y_test, pred, average = 'weighted')).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('F1 score',f1))\n",
    "\n",
    "# #ROC curve\n",
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred)\n",
    "# roc_auc = (auc(false_positive_rate, true_positive_rate)).astype('float64')\n",
    "# print('{:>10}: {:0.2%}'.format('ROC score',roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'KNN, Math vs Relax'\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It's a little better than random..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per Subject Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>low_alpha</th>\n",
       "      <th>high_alpha</th>\n",
       "      <th>low_beta</th>\n",
       "      <th>high_beta</th>\n",
       "      <th>low_gamma</th>\n",
       "      <th>mid+gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1158761.0</td>\n",
       "      <td>122862.0</td>\n",
       "      <td>31168.0</td>\n",
       "      <td>68083.0</td>\n",
       "      <td>46057.0</td>\n",
       "      <td>15456.0</td>\n",
       "      <td>9768.0</td>\n",
       "      <td>3260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>389639.0</td>\n",
       "      <td>48498.0</td>\n",
       "      <td>13741.0</td>\n",
       "      <td>10362.0</td>\n",
       "      <td>12736.0</td>\n",
       "      <td>15956.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>3610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>710350.0</td>\n",
       "      <td>60130.0</td>\n",
       "      <td>11277.0</td>\n",
       "      <td>16637.0</td>\n",
       "      <td>41050.0</td>\n",
       "      <td>34083.0</td>\n",
       "      <td>19829.0</td>\n",
       "      <td>18299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>342096.0</td>\n",
       "      <td>13945.0</td>\n",
       "      <td>9479.0</td>\n",
       "      <td>3609.0</td>\n",
       "      <td>4962.0</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>377172.0</td>\n",
       "      <td>77455.0</td>\n",
       "      <td>63315.0</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>4283.0</td>\n",
       "      <td>16340.0</td>\n",
       "      <td>6204.0</td>\n",
       "      <td>1290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26207</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>16168.0</td>\n",
       "      <td>4363.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>9654.0</td>\n",
       "      <td>6726.0</td>\n",
       "      <td>62302.0</td>\n",
       "      <td>79924.0</td>\n",
       "      <td>8924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26208</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>37818.0</td>\n",
       "      <td>11935.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>13823.0</td>\n",
       "      <td>29309.0</td>\n",
       "      <td>63970.0</td>\n",
       "      <td>32055.0</td>\n",
       "      <td>19320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26209</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>264800.0</td>\n",
       "      <td>89151.0</td>\n",
       "      <td>13650.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>8963.0</td>\n",
       "      <td>21334.0</td>\n",
       "      <td>20599.0</td>\n",
       "      <td>8955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26210</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>6675.0</td>\n",
       "      <td>7446.0</td>\n",
       "      <td>3403.0</td>\n",
       "      <td>4497.0</td>\n",
       "      <td>68995.0</td>\n",
       "      <td>30822.0</td>\n",
       "      <td>10568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26211</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>577033.0</td>\n",
       "      <td>21286.0</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>6076.0</td>\n",
       "      <td>10917.0</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>44177.0</td>\n",
       "      <td>9853.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1870 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  label      delta     theta  low_alpha  high_alpha  low_beta  \\\n",
       "690     8      0  1158761.0  122862.0    31168.0     68083.0   46057.0   \n",
       "691     8      0   389639.0   48498.0    13741.0     10362.0   12736.0   \n",
       "692     8      0   710350.0   60130.0    11277.0     16637.0   41050.0   \n",
       "693     8      0   342096.0   13945.0     9479.0      3609.0    4962.0   \n",
       "694     8      0   377172.0   77455.0    63315.0      6237.0    4283.0   \n",
       "...    ..    ...        ...       ...        ...         ...       ...   \n",
       "26207  27      1    16168.0    4363.0      669.0      9654.0    6726.0   \n",
       "26208  27      1    37818.0   11935.0      996.0     13823.0   29309.0   \n",
       "26209  27      1   264800.0   89151.0    13650.0      4509.0    8963.0   \n",
       "26210  27      1     3530.0    6675.0     7446.0      3403.0    4497.0   \n",
       "26211  27      1   577033.0   21286.0    11050.0      6076.0   10917.0   \n",
       "\n",
       "       high_beta  low_gamma  mid+gamma  \n",
       "690      15456.0     9768.0     3260.0  \n",
       "691      15956.0     3565.0     3610.0  \n",
       "692      34083.0    19829.0    18299.0  \n",
       "693       2477.0     1346.0      474.0  \n",
       "694      16340.0     6204.0     1290.0  \n",
       "...          ...        ...        ...  \n",
       "26207    62302.0    79924.0     8924.0  \n",
       "26208    63970.0    32055.0    19320.0  \n",
       "26209    21334.0    20599.0     8955.0  \n",
       "26210    68995.0    30822.0    10568.0  \n",
       "26211    49800.0    44177.0     9853.0  \n",
       "\n",
       "[1870 rows x 10 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_relax_trim = math_relax.drop(['Unnamed: 0', 'indra_time','reading_time', 'browser_latency', 'eeg_power', 'raw_values',\n",
    "       'signal_quality', 'createdAt', 'updatedAt', 'Session', 'Seen video before?', 'Chosen color',\n",
    "       'Saw icons?', 'Gender', 'Wear contacts','attention_esense','meditation_esense'], axis = 1)\n",
    "math_relax_trim.loc[math_relax_trim.label == 'relax','label'] = 0\n",
    "math_relax_trim.loc[math_relax_trim.label == 'math','label'] = 1\n",
    "math_relax_trim['label'] = math_relax_trim.label.astype(int)\n",
    "math_relax_trim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 Results with CV accuracy of 0.8666666666666666 \n",
      "\n",
      "[1.         0.75       1.         0.91666667 0.66666667]\n",
      "[1.         1.         1.         0.83333333 0.5       ]\n",
      "[1.         0.66666667 1.         1.         0.75      ]\n",
      "[1.         0.8        1.         0.90909091 0.6       ]\n",
      "Subject 2 Results with CV accuracy of 0.4935897435897436 \n",
      "\n",
      "[0.38461538 0.5        0.41666667 0.5        0.66666667]\n",
      "[0.42857143 0.33333333 0.5        0.5        0.66666667]\n",
      "[0.42857143 0.5        0.42857143 0.5        0.66666667]\n",
      "[0.42857143 0.4        0.46153846 0.5        0.66666667]\n",
      "Subject 3 Results with CV accuracy of 0.8621212121212121 \n",
      "\n",
      "[0.83333333 1.         0.91666667 0.83333333 0.72727273]\n",
      "[0.83333333 1.         1.         1.         0.66666667]\n",
      "[0.83333333 1.         0.875      0.77777778 0.8       ]\n",
      "[0.83333333 1.         0.93333333 0.875      0.72727273]\n",
      "Subject 4 Results with CV accuracy of 0.5948717948717948 \n",
      "\n",
      "[0.69230769 0.61538462 0.75       0.5        0.41666667]\n",
      "[0.83333333 0.57142857 0.83333333 0.66666667 0.83333333]\n",
      "[0.625      0.66666667 0.71428571 0.5        0.45454545]\n",
      "[0.71428571 0.61538462 0.76923077 0.57142857 0.58823529]\n",
      "Subject 5 Results with CV accuracy of 0.7884615384615385 \n",
      "\n",
      "[0.69230769 0.66666667 1.         0.75       0.83333333]\n",
      "[0.83333333 1.         1.         0.83333333 0.83333333]\n",
      "[0.625      0.6        1.         0.71428571 0.83333333]\n",
      "[0.71428571 0.75       1.         0.76923077 0.83333333]\n",
      "Subject 6 Results with CV accuracy of 0.6333333333333332 \n",
      "\n",
      "[0.75       0.66666667 0.66666667 0.66666667 0.41666667]\n",
      "[0.5        0.66666667 1.         0.83333333 0.33333333]\n",
      "[1.         0.66666667 0.6        0.625      0.4       ]\n",
      "[0.66666667 0.66666667 0.75       0.71428571 0.36363636]\n",
      "Subject 7 Results with CV accuracy of 0.6602564102564102 \n",
      "\n",
      "[0.38461538 0.5        0.75       0.75       0.91666667]\n",
      "[0.5        0.83333333 1.         0.83333333 0.83333333]\n",
      "[0.375      0.5        0.66666667 0.71428571 1.        ]\n",
      "[0.42857143 0.625      0.8        0.76923077 0.90909091]\n",
      "Subject 8 Results with CV accuracy of 0.6166666666666666 \n",
      "\n",
      "[0.5        0.58333333 0.66666667 0.66666667 0.66666667]\n",
      "[0.66666667 0.83333333 0.83333333 0.66666667 0.5       ]\n",
      "[0.5        0.55555556 0.625      0.66666667 0.75      ]\n",
      "[0.57142857 0.66666667 0.71428571 0.66666667 0.6       ]\n",
      "Subject 9 Results with CV accuracy of 0.7666666666666667 \n",
      "\n",
      "[0.75       0.83333333 0.83333333 0.91666667 0.5       ]\n",
      "[0.5        0.66666667 1.         1.         0.66666667]\n",
      "[1.         1.         0.75       0.85714286 0.5       ]\n",
      "[0.66666667 0.8        0.85714286 0.92307692 0.57142857]\n",
      "Subject 10 Results with CV accuracy of 0.65 \n",
      "\n",
      "[0.25       0.66666667 0.58333333 0.83333333 0.91666667]\n",
      "[0.         0.5        0.66666667 1.         1.        ]\n",
      "[0.         0.75       0.57142857 0.75       0.85714286]\n",
      "[0.         0.6        0.61538462 0.85714286 0.92307692]\n",
      "Subject 11 Results with CV accuracy of 0.6217948717948718 \n",
      "\n",
      "[0.69230769 0.83333333 0.41666667 0.5        0.66666667]\n",
      "[0.66666667 0.83333333 0.5        0.33333333 0.83333333]\n",
      "[0.66666667 0.83333333 0.42857143 0.5        0.625     ]\n",
      "[0.66666667 0.83333333 0.46153846 0.4        0.71428571]\n",
      "Subject 12 Results with CV accuracy of 0.6166666666666666 \n",
      "\n",
      "[0.41666667 0.66666667 0.58333333 0.75       0.66666667]\n",
      "[0.33333333 0.83333333 0.5        0.66666667 0.66666667]\n",
      "[0.4        0.625      0.6        0.8        0.66666667]\n",
      "[0.36363636 0.71428571 0.54545455 0.72727273 0.66666667]\n",
      "Subject 13 Results with CV accuracy of 0.8666666666666666 \n",
      "\n",
      "[0.75       0.83333333 0.91666667 0.91666667 0.91666667]\n",
      "[1.         0.83333333 0.83333333 0.83333333 0.83333333]\n",
      "[0.66666667 0.83333333 1.         1.         1.        ]\n",
      "[0.8        0.83333333 0.90909091 0.90909091 0.90909091]\n",
      "Subject 14 Results with CV accuracy of 0.7166666666666667 \n",
      "\n",
      "[0.75       0.66666667 0.58333333 0.75       0.83333333]\n",
      "[1.         0.66666667 0.33333333 0.83333333 0.83333333]\n",
      "[0.66666667 0.66666667 0.66666667 0.71428571 0.83333333]\n",
      "[0.8        0.66666667 0.44444444 0.76923077 0.83333333]\n",
      "Subject 15 Results with CV accuracy of 0.4621212121212121 \n",
      "\n",
      "[0.41666667 0.58333333 0.58333333 0.45454545 0.27272727]\n",
      "[0.5        0.83333333 0.5        0.8        0.33333333]\n",
      "[0.42857143 0.55555556 0.6        0.44444444 0.33333333]\n",
      "[0.46153846 0.66666667 0.54545455 0.57142857 0.33333333]\n",
      "Subject 16 Results with CV accuracy of 0.65 \n",
      "\n",
      "[0.58333333 0.33333333 0.66666667 0.91666667 0.75      ]\n",
      "[0.66666667 0.33333333 0.83333333 0.83333333 0.66666667]\n",
      "[0.57142857 0.33333333 0.625      1.         0.8       ]\n",
      "[0.61538462 0.33333333 0.71428571 0.90909091 0.72727273]\n",
      "Subject 17 Results with CV accuracy of 0.6076923076923076 \n",
      "\n",
      "[0.53846154 0.5        0.75       0.58333333 0.66666667]\n",
      "[0.66666667 0.16666667 0.66666667 0.66666667 0.83333333]\n",
      "[0.5        0.5        0.8        0.57142857 0.625     ]\n",
      "[0.57142857 0.25       0.72727273 0.61538462 0.71428571]\n",
      "Subject 18 Results with CV accuracy of 0.5666666666666667 \n",
      "\n",
      "[0.66666667 0.5        0.41666667 0.75       0.5       ]\n",
      "[0.83333333 0.66666667 0.66666667 1.         0.5       ]\n",
      "[0.625      0.5        0.44444444 0.66666667 0.5       ]\n",
      "[0.71428571 0.57142857 0.53333333 0.8        0.5       ]\n",
      "Subject 19 Results with CV accuracy of 0.8423076923076923 \n",
      "\n",
      "[0.84615385 0.84615385 0.92307692 0.84615385 0.75      ]\n",
      "[0.66666667 1.         1.         1.         0.5       ]\n",
      "[1.         0.77777778 0.875      0.77777778 1.        ]\n",
      "[0.8        0.875      0.93333333 0.875      0.66666667]\n",
      "Subject 20 Results with CV accuracy of 0.55 \n",
      "\n",
      "[0.58333333 0.41666667 0.58333333 0.75       0.41666667]\n",
      "[1.  0.  0.5 0.5 0.5]\n",
      "[0.54545455 0.         0.6        1.         0.42857143]\n",
      "[0.70588235 0.         0.54545455 0.66666667 0.46153846]\n",
      "Subject 21 Results with CV accuracy of 0.6666666666666666 \n",
      "\n",
      "[0.66666667 0.41666667 0.75       0.83333333 0.66666667]\n",
      "[1.         0.83333333 0.5        0.66666667 0.66666667]\n",
      "[0.6        0.45454545 1.         1.         0.66666667]\n",
      "[0.75       0.58823529 0.66666667 0.8        0.66666667]\n",
      "Subject 22 Results with CV accuracy of 0.4666666666666667 \n",
      "\n",
      "[0.58333333 0.75       0.16666667 0.58333333 0.25      ]\n",
      "[0.66666667 0.83333333 0.33333333 0.5        0.33333333]\n",
      "[0.57142857 0.71428571 0.25       0.6        0.28571429]\n",
      "[0.61538462 0.76923077 0.28571429 0.54545455 0.30769231]\n",
      "Subject 23 Results with CV accuracy of 0.5 \n",
      "\n",
      "[0.41666667 0.41666667 0.41666667 0.58333333 0.66666667]\n",
      "[0.83333333 0.66666667 0.5        0.5        0.66666667]\n",
      "[0.45454545 0.44444444 0.42857143 0.6        0.66666667]\n",
      "[0.58823529 0.53333333 0.46153846 0.54545455 0.66666667]\n",
      "Subject 24 Results with CV accuracy of 0.7666666666666667 \n",
      "\n",
      "[0.5        0.83333333 0.66666667 1.         0.83333333]\n",
      "[0.83333333 0.83333333 0.5        1.         0.66666667]\n",
      "[0.5        0.83333333 0.75       1.         1.        ]\n",
      "[0.625      0.83333333 0.6        1.         0.8       ]\n",
      "Subject 25 Results with CV accuracy of 0.4 \n",
      "\n",
      "[0.58333333 0.25       0.41666667 0.5        0.25      ]\n",
      "[0.33333333 0.33333333 0.16666667 0.66666667 0.5       ]\n",
      "[0.66666667 0.28571429 0.33333333 0.5        0.33333333]\n",
      "[0.44444444 0.30769231 0.22222222 0.57142857 0.4       ]\n",
      "Subject 26 Results with CV accuracy of 0.4564102564102564 \n",
      "\n",
      "[0.61538462 0.33333333 0.58333333 0.41666667 0.33333333]\n",
      "[0.66666667 0.5        0.33333333 0.5        0.33333333]\n",
      "[0.57142857 0.375      0.66666667 0.42857143 0.33333333]\n",
      "[0.61538462 0.42857143 0.44444444 0.46153846 0.33333333]\n",
      "Subject 27 Results with CV accuracy of 0.7166666666666667 \n",
      "\n",
      "[0.75       0.66666667 0.83333333 0.75       0.58333333]\n",
      "[0.5        0.5        0.83333333 0.5        0.66666667]\n",
      "[1.         0.75       0.83333333 1.         0.57142857]\n",
      "[0.66666667 0.6        0.83333333 0.66666667 0.61538462]\n",
      "Subject 28 Results with CV accuracy of 0.5333333333333333 \n",
      "\n",
      "[0.66666667 0.5        0.33333333 0.58333333 0.58333333]\n",
      "[0.5        0.33333333 0.33333333 0.5        0.66666667]\n",
      "[0.75       0.5        0.33333333 0.6        0.57142857]\n",
      "[0.6        0.4        0.33333333 0.54545455 0.61538462]\n",
      "Subject 29 Results with CV accuracy of 0.6833333333333333 \n",
      "\n",
      "[0.33333333 0.91666667 0.83333333 0.66666667 0.66666667]\n",
      "[0.66666667 0.83333333 0.83333333 0.66666667 0.83333333]\n",
      "[0.4        1.         0.83333333 0.66666667 0.625     ]\n",
      "[0.5        0.90909091 0.83333333 0.66666667 0.71428571]\n",
      "Subject 30 Results with CV accuracy of 0.5256410256410257 \n",
      "\n",
      "[0.46153846 0.5        0.58333333 0.5        0.58333333]\n",
      "[0.66666667 0.5        0.66666667 0.33333333 0.33333333]\n",
      "[0.44444444 0.5        0.57142857 0.5        0.66666667]\n",
      "[0.53333333 0.5        0.61538462 0.4        0.44444444]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "accuracy_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "f1_list = [] \n",
    "\n",
    "\n",
    "for i in range(1,31):\n",
    "    subject = math_relax_trim[math_relax_trim['id'] == i]\n",
    "    features = subject.drop(['id', 'label'], axis = 1)\n",
    "    accuracy_all = cross_val_score(knn, features, subject['label'], \n",
    "                             cv = 5, scoring = 'accuracy')\n",
    "    precision_all = cross_val_score(knn, features, subject['label'], \n",
    "                             cv = 5, scoring = 'precision') \n",
    "    recall_all = cross_val_score(knn, features, subject['label'], \n",
    "                             cv = 5, scoring = 'recall')\n",
    "    f1_all= cross_val_score(knn, features, subject['label'], \n",
    "                             cv = 5, scoring = 'f1')\n",
    "    accuracy_list.append(accuracy_all.mean())\n",
    "    precision_list.append(precision_all.mean())\n",
    "    recall_list.append(recall_all.mean())\n",
    "    f1_list.append(f1_all.mean())\n",
    "    print(f'Subject {i} Results with CV accuracy of {accuracy_all.mean()} \\n')\n",
    "    print(accuracy_all)\n",
    "    print(recall_all)\n",
    "    print(precision_all)\n",
    "    print(f1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "precision = sum(precision_list)/len(precision_list)\n",
    "recall = sum(recall_list)/len(recall_list)\n",
    "f1 = sum(f1_list)/len(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.6382867132867133\n",
      "precision is 0.6512881192881196\n",
      "recall is 0.6697777777777776\n",
      "d1_score is 0.642859588124294\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy is {accuracy}')\n",
    "print(f'precision is {precision}')\n",
    "print(f'recall is {recall}')\n",
    "print(f'd1_score is {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'KNN, Math vs Relax, per Subject Cross Validation'\n",
    "\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_esense</th>\n",
       "      <th>meditation_esense</th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>low_alpha</th>\n",
       "      <th>high_alpha</th>\n",
       "      <th>low_beta</th>\n",
       "      <th>high_beta</th>\n",
       "      <th>low_gamma</th>\n",
       "      <th>mid+gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>1158761.0</td>\n",
       "      <td>122862.0</td>\n",
       "      <td>31168.0</td>\n",
       "      <td>68083.0</td>\n",
       "      <td>46057.0</td>\n",
       "      <td>15456.0</td>\n",
       "      <td>9768.0</td>\n",
       "      <td>3260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>389639.0</td>\n",
       "      <td>48498.0</td>\n",
       "      <td>13741.0</td>\n",
       "      <td>10362.0</td>\n",
       "      <td>12736.0</td>\n",
       "      <td>15956.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>3610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>710350.0</td>\n",
       "      <td>60130.0</td>\n",
       "      <td>11277.0</td>\n",
       "      <td>16637.0</td>\n",
       "      <td>41050.0</td>\n",
       "      <td>34083.0</td>\n",
       "      <td>19829.0</td>\n",
       "      <td>18299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>342096.0</td>\n",
       "      <td>13945.0</td>\n",
       "      <td>9479.0</td>\n",
       "      <td>3609.0</td>\n",
       "      <td>4962.0</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>38</td>\n",
       "      <td>78</td>\n",
       "      <td>377172.0</td>\n",
       "      <td>77455.0</td>\n",
       "      <td>63315.0</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>4283.0</td>\n",
       "      <td>16340.0</td>\n",
       "      <td>6204.0</td>\n",
       "      <td>1290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26207</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>16168.0</td>\n",
       "      <td>4363.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>9654.0</td>\n",
       "      <td>6726.0</td>\n",
       "      <td>62302.0</td>\n",
       "      <td>79924.0</td>\n",
       "      <td>8924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26208</th>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>37818.0</td>\n",
       "      <td>11935.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>13823.0</td>\n",
       "      <td>29309.0</td>\n",
       "      <td>63970.0</td>\n",
       "      <td>32055.0</td>\n",
       "      <td>19320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26209</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>264800.0</td>\n",
       "      <td>89151.0</td>\n",
       "      <td>13650.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>8963.0</td>\n",
       "      <td>21334.0</td>\n",
       "      <td>20599.0</td>\n",
       "      <td>8955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26210</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>6675.0</td>\n",
       "      <td>7446.0</td>\n",
       "      <td>3403.0</td>\n",
       "      <td>4497.0</td>\n",
       "      <td>68995.0</td>\n",
       "      <td>30822.0</td>\n",
       "      <td>10568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26211</th>\n",
       "      <td>94</td>\n",
       "      <td>11</td>\n",
       "      <td>577033.0</td>\n",
       "      <td>21286.0</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>6076.0</td>\n",
       "      <td>10917.0</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>44177.0</td>\n",
       "      <td>9853.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1870 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       attention_esense  meditation_esense      delta     theta  low_alpha  \\\n",
       "690                  27                 64  1158761.0  122862.0    31168.0   \n",
       "691                  34                 64   389639.0   48498.0    13741.0   \n",
       "692                  34                 64   710350.0   60130.0    11277.0   \n",
       "693                  34                 64   342096.0   13945.0     9479.0   \n",
       "694                  38                 78   377172.0   77455.0    63315.0   \n",
       "...                 ...                ...        ...       ...        ...   \n",
       "26207               100                 20    16168.0    4363.0      669.0   \n",
       "26208               100                 11    37818.0   11935.0      996.0   \n",
       "26209               100                 10   264800.0   89151.0    13650.0   \n",
       "26210               100                  8     3530.0    6675.0     7446.0   \n",
       "26211                94                 11   577033.0   21286.0    11050.0   \n",
       "\n",
       "       high_alpha  low_beta  high_beta  low_gamma  mid+gamma  \n",
       "690       68083.0   46057.0    15456.0     9768.0     3260.0  \n",
       "691       10362.0   12736.0    15956.0     3565.0     3610.0  \n",
       "692       16637.0   41050.0    34083.0    19829.0    18299.0  \n",
       "693        3609.0    4962.0     2477.0     1346.0      474.0  \n",
       "694        6237.0    4283.0    16340.0     6204.0     1290.0  \n",
       "...           ...       ...        ...        ...        ...  \n",
       "26207      9654.0    6726.0    62302.0    79924.0     8924.0  \n",
       "26208     13823.0   29309.0    63970.0    32055.0    19320.0  \n",
       "26209      4509.0    8963.0    21334.0    20599.0     8955.0  \n",
       "26210      3403.0    4497.0    68995.0    30822.0    10568.0  \n",
       "26211      6076.0   10917.0    49800.0    44177.0     9853.0  \n",
       "\n",
       "[1870 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_svm (X,y,n):\n",
    "    clf = svm.SVC()\n",
    "    scores = cross_val_score(clf, X, y, cv=n)\n",
    "    return scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectors_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e325cba33353>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectors_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meeg_power\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meeg_power\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcross_val_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectors_labels' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = \n",
    "cross_val_svm(X,y,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = math_relax.drop(['Unnamed: 0', 'id', 'indra_time','reading_time', 'browser_latency', 'eeg_power', 'raw_values',\n",
    "       'signal_quality', 'createdAt', 'updatedAt', 'Session', 'Seen video before?', 'Chosen color',\n",
    "       'Saw icons?', 'Gender', 'Wear contacts','label'], axis = 1)\n",
    "scaled_data = scaler.fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,math_relax['label'], test_size=0.30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        math       0.53      0.63      0.57       262\n",
      "       relax       0.61      0.50      0.55       299\n",
      "\n",
      "    accuracy                           0.56       561\n",
      "   macro avg       0.57      0.57      0.56       561\n",
      "weighted avg       0.57      0.56      0.56       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 56.15%\n",
      " Precision: 52.55%\n",
      "    Recall: 62.98%\n",
      "  F1 score: 57.29%\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy/precision/recall/f1\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = (accuracy_score(y_test, pred)).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Accuracy',accuracy))\n",
    "# precision tp / (tp + fp)\n",
    "precision = (precision_score(y_test, pred, pos_label = 'math' )).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Precision',precision))\n",
    "# recall: tp / (tp + fn)\n",
    "recall = (recall_score(y_test, pred, pos_label = 'math' )).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Recall',recall))\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = (f1_score(y_test, pred, pos_label = 'math' )).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('F1 score',f1))\n",
    "\n",
    "#ROC curve\n",
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred, pos_label = 'math' )\n",
    "# roc_auc = (auc(false_positive_rate, true_positive_rate)).astype('float64')\n",
    "# print('{:>10}: {:0.2%}'.format('ROC score',roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Logistic Regression'\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around the same percentages reached with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5978609625668448"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(logmodel, scaled_data, math_relax['label'], \n",
    "                             cv = 10, scoring = 'accuracy')  \n",
    "accuracy = scores.mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6073667864560359"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_scores = cross_val_score(logmodel, scaled_data, math_relax_trim['label'], \n",
    "                             cv = 10, scoring = 'precision') \n",
    "precision = precision_scores.mean()\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5929764355982613"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_scores = cross_val_score(logmodel, scaled_data, math_relax_trim['label'], \n",
    "                             cv = 10, scoring = 'recall') \n",
    "recall = recall_scores.mean()\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5846171859089114"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores = cross_val_score(logmodel, scaled_data, math_relax_trim['label'], \n",
    "                             cv = 10, scoring = 'f1') \n",
    "f1 = f1_scores.mean()\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Logistic Regression, Cross Validated'\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Per Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 Results with CV accuracy of 0.8833333333333332 \n",
      "\n",
      "[0.83333333 1.         0.91666667 0.91666667 0.75      ]\n",
      "[0.83333333 1.         1.         0.83333333 0.5       ]\n",
      "[0.83333333 1.         0.85714286 1.         1.        ]\n",
      "[0.83333333 1.         0.92307692 0.90909091 0.66666667]\n",
      "Subject 2 Results with CV accuracy of 0.5294871794871795 \n",
      "\n",
      "[0.23076923 0.58333333 0.75       0.33333333 0.75      ]\n",
      "[0.28571429 0.33333333 1.         0.16666667 0.66666667]\n",
      "[0.28571429 0.66666667 0.66666667 0.25       0.8       ]\n",
      "[0.28571429 0.44444444 0.8        0.2        0.72727273]\n",
      "Subject 3 Results with CV accuracy of 0.8621212121212121 \n",
      "\n",
      "[0.91666667 1.         0.83333333 0.83333333 0.72727273]\n",
      "[0.83333333 1.         1.         1.         0.66666667]\n",
      "[1.         1.         0.77777778 0.77777778 0.8       ]\n",
      "[0.90909091 1.         0.875      0.875      0.72727273]\n",
      "Subject 4 Results with CV accuracy of 0.3833333333333333 \n",
      "\n",
      "[0.46153846 0.53846154 0.5        0.33333333 0.08333333]\n",
      "[0.16666667 0.42857143 0.33333333 0.16666667 0.        ]\n",
      "[0.33333333 0.6        0.5        0.25       0.        ]\n",
      "[0.22222222 0.5        0.4        0.2        0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 5 Results with CV accuracy of 0.7410256410256411 \n",
      "\n",
      "[0.53846154 0.66666667 1.         0.83333333 0.66666667]\n",
      "[1.         1.         1.         0.66666667 0.33333333]\n",
      "[0.5 0.6 1.  1.  1. ]\n",
      "[0.66666667 0.75       1.         0.8        0.5       ]\n",
      "Subject 6 Results with CV accuracy of 0.5833333333333333 \n",
      "\n",
      "[0.58333333 0.83333333 0.41666667 0.41666667 0.66666667]\n",
      "[0.5        0.83333333 0.5        0.16666667 0.5       ]\n",
      "[0.6        0.83333333 0.42857143 0.33333333 0.75      ]\n",
      "[0.54545455 0.83333333 0.46153846 0.22222222 0.6       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 7 Results with CV accuracy of 0.7038461538461538 \n",
      "\n",
      "[0.76923077 0.5        0.58333333 0.75       0.91666667]\n",
      "[0.83333333 0.83333333 0.16666667 0.66666667 0.83333333]\n",
      "[0.71428571 0.5        1.         0.8        1.        ]\n",
      "[0.76923077 0.625      0.28571429 0.72727273 0.90909091]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 8 Results with CV accuracy of 0.6500000000000001 \n",
      "\n",
      "[0.41666667 0.75       0.75       0.75       0.58333333]\n",
      "[0.5        0.83333333 0.66666667 0.66666667 0.33333333]\n",
      "[0.42857143 0.71428571 0.8        0.8        0.66666667]\n",
      "[0.46153846 0.76923077 0.72727273 0.72727273 0.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 9 Results with CV accuracy of 0.6666666666666666 \n",
      "\n",
      "[0.66666667 0.66666667 0.58333333 0.75       0.66666667]\n",
      "[0.5        0.66666667 0.5        0.83333333 0.66666667]\n",
      "[0.75       0.66666667 0.6        0.71428571 0.66666667]\n",
      "[0.6        0.66666667 0.54545455 0.76923077 0.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 10 Results with CV accuracy of 0.6333333333333333 \n",
      "\n",
      "[0.16666667 0.75       0.5        0.75       1.        ]\n",
      "[0.         0.5        0.83333333 0.83333333 1.        ]\n",
      "[0.         1.         0.5        0.71428571 1.        ]\n",
      "[0.         0.66666667 0.625      0.76923077 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 11 Results with CV accuracy of 0.7269230769230768 \n",
      "\n",
      "[0.38461538 0.75       0.91666667 0.91666667 0.66666667]\n",
      "[0.5        0.66666667 0.83333333 0.83333333 0.66666667]\n",
      "[0.375      0.8        1.         1.         0.66666667]\n",
      "[0.42857143 0.72727273 0.90909091 0.90909091 0.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 12 Results with CV accuracy of 0.6333333333333334 \n",
      "\n",
      "[0.41666667 0.83333333 0.75       0.58333333 0.58333333]\n",
      "[0.66666667 0.66666667 0.5        0.5        0.66666667]\n",
      "[0.44444444 1.         1.         0.6        0.57142857]\n",
      "[0.53333333 0.8        0.66666667 0.54545455 0.61538462]\n",
      "Subject 13 Results with CV accuracy of 0.8833333333333332 \n",
      "\n",
      "[0.58333333 1.         0.91666667 0.91666667 1.        ]\n",
      "[0.83333333 1.         0.83333333 0.83333333 1.        ]\n",
      "[0.55555556 1.         1.         1.         1.        ]\n",
      "[0.66666667 1.         0.90909091 0.90909091 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 14 Results with CV accuracy of 0.7166666666666666 \n",
      "\n",
      "[0.66666667 0.66666667 0.75       0.66666667 0.83333333]\n",
      "[1.         0.83333333 0.5        0.33333333 0.83333333]\n",
      "[0.6        0.625      1.         1.         0.83333333]\n",
      "[0.75       0.71428571 0.66666667 0.5        0.83333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 15 Results with CV accuracy of 0.5333333333333333 \n",
      "\n",
      "[0.58333333 0.58333333 0.5        0.54545455 0.45454545]\n",
      "[0.83333333 0.83333333 0.16666667 0.4        0.83333333]\n",
      "[0.55555556 0.55555556 0.5        0.5        0.5       ]\n",
      "[0.66666667 0.66666667 0.25       0.44444444 0.625     ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 16 Results with CV accuracy of 0.6333333333333333 \n",
      "\n",
      "[0.5        0.75       0.5        0.66666667 0.75      ]\n",
      "[0.66666667 0.66666667 0.33333333 0.33333333 0.66666667]\n",
      "[0.5 0.8 0.5 1.  0.8]\n",
      "[0.57142857 0.72727273 0.4        0.5        0.72727273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 17 Results with CV accuracy of 0.4948717948717949 \n",
      "\n",
      "[0.30769231 0.58333333 0.58333333 0.5        0.5       ]\n",
      "[0.5        0.5        0.5        0.5        0.66666667]\n",
      "[0.33333333 0.6        0.6        0.5        0.5       ]\n",
      "[0.4        0.54545455 0.54545455 0.5        0.57142857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 18 Results with CV accuracy of 0.5333333333333333 \n",
      "\n",
      "[0.66666667 0.33333333 0.41666667 0.58333333 0.66666667]\n",
      "[0.5        0.16666667 0.16666667 0.5        0.66666667]\n",
      "[0.75       0.25       0.33333333 0.6        0.66666667]\n",
      "[0.6        0.2        0.22222222 0.54545455 0.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 19 Results with CV accuracy of 0.8602564102564102 \n",
      "\n",
      "[0.92307692 0.84615385 0.76923077 0.84615385 0.91666667]\n",
      "[0.83333333 1.         0.85714286 1.         0.83333333]\n",
      "[1.         0.77777778 0.75       0.77777778 1.        ]\n",
      "[0.90909091 0.875      0.8        0.875      0.90909091]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 20 Results with CV accuracy of 0.5333333333333333 \n",
      "\n",
      "[0.5        0.41666667 0.5        0.58333333 0.66666667]\n",
      "[1.         0.5        0.16666667 0.5        0.5       ]\n",
      "[0.5        0.42857143 0.5        0.6        0.75      ]\n",
      "[0.66666667 0.46153846 0.25       0.54545455 0.6       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 21 Results with CV accuracy of 0.7166666666666668 \n",
      "\n",
      "[0.58333333 0.5        0.83333333 0.83333333 0.83333333]\n",
      "[0.83333333 0.16666667 0.66666667 0.66666667 0.83333333]\n",
      "[0.55555556 0.5        1.         1.         0.83333333]\n",
      "[0.66666667 0.25       0.8        0.8        0.83333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 22 Results with CV accuracy of 0.6000000000000001 \n",
      "\n",
      "[0.83333333 0.58333333 0.75       0.25       0.58333333]\n",
      "[0.83333333 0.5        0.66666667 0.16666667 0.5       ]\n",
      "[0.83333333 0.6        0.8        0.2        0.6       ]\n",
      "[0.83333333 0.54545455 0.72727273 0.18181818 0.54545455]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 23 Results with CV accuracy of 0.4833333333333334 \n",
      "\n",
      "[0.58333333 0.41666667 0.5        0.41666667 0.5       ]\n",
      "[0.83333333 0.33333333 0.5        0.33333333 0.16666667]\n",
      "[0.55555556 0.4        0.5        0.4        0.5       ]\n",
      "[0.66666667 0.36363636 0.5        0.36363636 0.25      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 24 Results with CV accuracy of 0.7166666666666667 \n",
      "\n",
      "[0.58333333 0.75       0.75       0.83333333 0.66666667]\n",
      "[0.66666667 0.83333333 0.66666667 0.66666667 0.83333333]\n",
      "[0.57142857 0.71428571 0.8        1.         0.625     ]\n",
      "[0.61538462 0.76923077 0.72727273 0.8        0.71428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 25 Results with CV accuracy of 0.4833333333333333 \n",
      "\n",
      "[0.41666667 0.58333333 0.41666667 0.58333333 0.41666667]\n",
      "[0.16666667 0.33333333 0.5        0.5        0.33333333]\n",
      "[0.33333333 0.66666667 0.42857143 0.6        0.4       ]\n",
      "[0.22222222 0.44444444 0.46153846 0.54545455 0.36363636]\n",
      "Subject 26 Results with CV accuracy of 0.4141025641025641 \n",
      "\n",
      "[0.15384615 0.41666667 0.5        0.5        0.5       ]\n",
      "[0.33333333 0.33333333 0.66666667 0.33333333 0.33333333]\n",
      "[0.22222222 0.4        0.5        0.5        0.5       ]\n",
      "[0.26666667 0.36363636 0.57142857 0.4        0.4       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 27 Results with CV accuracy of 0.8666666666666668 \n",
      "\n",
      "[0.66666667 1.         0.83333333 0.83333333 1.        ]\n",
      "[0.83333333 1.         0.83333333 0.83333333 1.        ]\n",
      "[0.625      1.         0.83333333 0.83333333 1.        ]\n",
      "[0.71428571 1.         0.83333333 0.83333333 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 28 Results with CV accuracy of 0.4 \n",
      "\n",
      "[0.5        0.25       0.41666667 0.41666667 0.41666667]\n",
      "[0.83333333 0.         0.33333333 0.5        0.5       ]\n",
      "[0.5        0.         0.4        0.42857143 0.42857143]\n",
      "[0.625      0.         0.36363636 0.46153846 0.46153846]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 29 Results with CV accuracy of 0.6666666666666666 \n",
      "\n",
      "[0.5        0.66666667 0.75       0.91666667 0.5       ]\n",
      "[0.33333333 0.66666667 0.83333333 1.         0.5       ]\n",
      "[0.5        0.66666667 0.71428571 0.85714286 0.5       ]\n",
      "[0.4        0.66666667 0.76923077 0.92307692 0.5       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Seran\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 30 Results with CV accuracy of 0.5089743589743589 \n",
      "\n",
      "[0.46153846 0.5        0.66666667 0.41666667 0.5       ]\n",
      "[0.5        0.5        0.66666667 0.33333333 0.66666667]\n",
      "[0.42857143 0.5        0.66666667 0.4        0.5       ]\n",
      "[0.46153846 0.5        0.66666667 0.36363636 0.57142857]\n"
     ]
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "accuracy_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "f1_list = [] \n",
    "\n",
    "for i in range(1,31):\n",
    "    subject = math_relax_trim[math_relax_trim['id'] == i]\n",
    "    features = subject.drop(['label'], axis = 1)\n",
    "    scaled_data = scaler.fit_transform(features)\n",
    "    accuracy_all = cross_val_score(logmodel, features, subject['label'], \n",
    "                             cv = 5, scoring = 'accuracy')\n",
    "    precision_all = cross_val_score(logmodel, features, subject['label'], \n",
    "                             cv = 5, scoring = 'precision') \n",
    "    recall_all = cross_val_score(logmodel, features, subject['label'], \n",
    "                             cv = 5, scoring = 'recall')\n",
    "    f1_all= cross_val_score(logmodel, features, subject['label'], \n",
    "                             cv = 5, scoring = 'f1')\n",
    "    accuracy_list.append(accuracy_all.mean())\n",
    "    precision_list.append(precision_all.mean())\n",
    "    recall_list.append(recall_all.mean())\n",
    "    f1_list.append(f1_all.mean())\n",
    "    print(f'Subject {i} Results with CV accuracy of {accuracy_all.mean()} \\n')\n",
    "    print(accuracy_all)\n",
    "    print(recall_all)\n",
    "    print(precision_all)\n",
    "    print(f1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "precision = sum(precision_list)/len(precision_list)\n",
    "recall = sum(recall_list)/len(recall_list)\n",
    "f1 = sum(f1_list)/len(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.6347202797202798\n",
      "precision is 0.6553386243386243\n",
      "recall is 0.610920634920635\n",
      "d1_score is 0.6117180597180598\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy is {accuracy}')\n",
    "print(f'precision is {precision}')\n",
    "print(f'recall is {recall}')\n",
    "print(f'd1_score is {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Logistic Regression, Math vs Relax, per Subject Cross Validation'\n",
    "\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "features = math_relax.drop(['Unnamed: 0', 'id', 'indra_time','reading_time', 'browser_latency', 'eeg_power', 'raw_values',\n",
    "       'signal_quality', 'createdAt', 'updatedAt', 'Session', 'Seen video before?', 'Chosen color',\n",
    "       'Saw icons?', 'Gender', 'Wear contacts','label'], axis = 1)\n",
    "scaled_data = scaler.fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,math_relax['label'], test_size=0.30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        math       0.60      0.62      0.61       289\n",
      "       relax       0.58      0.57      0.57       272\n",
      "\n",
      "    accuracy                           0.59       561\n",
      "   macro avg       0.59      0.59      0.59       561\n",
      "weighted avg       0.59      0.59      0.59       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = dtree.predict(X_test)\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[178 111]\n",
      " [118 154]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 59.18%\n",
      " Precision: 60.14%\n",
      "    Recall: 61.59%\n",
      "  F1 score: 60.85%\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy/precision/recall/f1\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = (accuracy_score(y_test, pred)).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Accuracy',accuracy))\n",
    "# precision tp / (tp + fp)\n",
    "precision = (precision_score(y_test, pred, pos_label = 'math' )).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Precision',precision))\n",
    "# recall: tp / (tp + fn)\n",
    "recall = (recall_score(y_test, pred, pos_label = 'math' )).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Recall',recall))\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = (f1_score(y_test, pred, pos_label = 'math' )).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('F1 score',f1))\n",
    "\n",
    "#ROC curve\n",
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred, pos_label = 'math' )\n",
    "# roc_auc = (auc(false_positive_rate, true_positive_rate)).astype('float64')\n",
    "# print('{:>10}: {:0.2%}'.format('ROC score',roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6037433155080214"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(dtree, scaled_data, math_relax['label'], \n",
    "                             cv = 10, scoring = 'accuracy')  \n",
    "mean_score = scores.mean()\n",
    "mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Decision Tree'\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than logistic regression and KNN by a couple percentage points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5978609625668448\n",
      "0.598434384966035\n",
      "0.5959849004804394\n",
      "0.5932231278431116\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dtree, scaled_data, math_relax['label'], \n",
    "                             cv = 10, scoring = 'accuracy')  \n",
    "accuracy = scores.mean()\n",
    "print(accuracy)\n",
    "\n",
    "precision_scores = cross_val_score(dtree, scaled_data, math_relax_trim['label'], \n",
    "                             cv = 10, scoring = 'precision') \n",
    "precision = precision_scores.mean()\n",
    "print(precision)\n",
    "\n",
    "recall_scores = cross_val_score(dtree, scaled_data, math_relax_trim['label'], \n",
    "                             cv = 10, scoring = 'recall') \n",
    "recall = recall_scores.mean()\n",
    "print(recall)\n",
    "\n",
    "f1_scores = cross_val_score(dtree, scaled_data, math_relax_trim['label'], \n",
    "                             cv = 10, scoring = 'f1') \n",
    "f1 = f1_scores.mean()\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Decision Tree, Cross Validated'\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree per Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 Results with CV accuracy of 0.8166666666666668 \n",
      "\n",
      "[0.83333333 0.83333333 0.91666667 0.83333333 0.66666667]\n",
      "[1.         1.         1.         0.83333333 0.5       ]\n",
      "[0.85714286 0.66666667 0.75       1.         0.75      ]\n",
      "[0.92307692 0.8        0.76923077 0.90909091 0.66666667]\n",
      "Subject 2 Results with CV accuracy of 0.5935897435897436 \n",
      "\n",
      "[0.38461538 0.83333333 0.58333333 0.5        0.66666667]\n",
      "[0.57142857 0.83333333 0.5        0.83333333 0.83333333]\n",
      "[0.44444444 0.83333333 0.75       0.5        0.625     ]\n",
      "[0.5        0.83333333 0.6        0.625      0.71428571]\n",
      "Subject 3 Results with CV accuracy of 0.7772727272727272 \n",
      "\n",
      "[0.75       0.83333333 0.91666667 0.75       0.63636364]\n",
      "[0.83333333 0.83333333 1.         0.85714286 0.5       ]\n",
      "[1.         0.83333333 0.875      0.75       0.8       ]\n",
      "[0.61538462 0.83333333 0.93333333 0.82352941 0.72727273]\n",
      "Subject 4 Results with CV accuracy of 0.4961538461538463 \n",
      "\n",
      "[0.84615385 0.38461538 0.58333333 0.33333333 0.33333333]\n",
      "[1.         0.42857143 0.5        0.5        0.5       ]\n",
      "[0.71428571 0.42857143 0.57142857 0.5        0.375     ]\n",
      "[0.76923077 0.46153846 0.66666667 0.57142857 0.42857143]\n",
      "Subject 5 Results with CV accuracy of 0.7230769230769231 \n",
      "\n",
      "[0.61538462 0.91666667 0.75       0.75       0.58333333]\n",
      "[1.         1.         0.5        0.5        0.33333333]\n",
      "[0.6        0.85714286 1.         0.75       1.        ]\n",
      "[0.66666667 0.92307692 0.66666667 0.72727273 0.5       ]\n",
      "Subject 6 Results with CV accuracy of 0.5333333333333334 \n",
      "\n",
      "[0.66666667 0.66666667 0.66666667 0.33333333 0.33333333]\n",
      "[0.66666667 0.66666667 0.5        0.16666667 0.33333333]\n",
      "[0.8        0.5        0.66666667 0.4        0.33333333]\n",
      "[0.72727273 0.61538462 0.76923077 0.2        0.33333333]\n",
      "Subject 7 Results with CV accuracy of 0.6076923076923078 \n",
      "\n",
      "[0.53846154 0.5        0.41666667 0.75       0.83333333]\n",
      "[0.66666667 0.83333333 0.33333333 0.83333333 1.        ]\n",
      "[0.5        0.5        0.57142857 0.71428571 1.        ]\n",
      "[0.57142857 0.66666667 0.36363636 0.83333333 0.8       ]\n",
      "Subject 8 Results with CV accuracy of 0.7 \n",
      "\n",
      "[0.66666667 0.83333333 0.75       0.83333333 0.41666667]\n",
      "[0.66666667 0.83333333 1.         0.83333333 0.5       ]\n",
      "[0.6        0.66666667 0.75       0.75       0.5       ]\n",
      "[0.8        0.85714286 0.76923077 0.76923077 0.57142857]\n",
      "Subject 9 Results with CV accuracy of 0.5666666666666667 \n",
      "\n",
      "[0.66666667 0.66666667 0.5        0.5        0.5       ]\n",
      "[0.5        0.66666667 0.83333333 0.66666667 0.66666667]\n",
      "[0.75       0.57142857 0.55555556 0.44444444 0.71428571]\n",
      "[0.72727273 0.66666667 0.57142857 0.46153846 0.57142857]\n",
      "Subject 10 Results with CV accuracy of 0.6 \n",
      "\n",
      "[0.41666667 0.66666667 0.66666667 0.66666667 0.58333333]\n",
      "[0.33333333 0.33333333 0.83333333 1.         0.83333333]\n",
      "[0.4        1.         0.625      0.66666667 1.        ]\n",
      "[0.36363636 0.4        0.71428571 0.8        0.44444444]\n",
      "Subject 11 Results with CV accuracy of 0.6782051282051282 \n",
      "\n",
      "[0.30769231 0.83333333 0.91666667 0.83333333 0.5       ]\n",
      "[0.33333333 0.83333333 0.66666667 0.5        0.66666667]\n",
      "[0.28571429 0.83333333 1.         1.         0.55555556]\n",
      "[0.42857143 0.83333333 0.72727273 0.8        0.57142857]\n",
      "Subject 12 Results with CV accuracy of 0.6 \n",
      "\n",
      "[0.66666667 0.58333333 0.75       0.66666667 0.33333333]\n",
      "[0.33333333 0.33333333 0.83333333 0.83333333 0.        ]\n",
      "[1.         0.66666667 0.625      0.66666667 0.33333333]\n",
      "[0.5        0.54545455 0.76923077 0.76923077 0.2       ]\n",
      "Subject 13 Results with CV accuracy of 0.8 \n",
      "\n",
      "[0.66666667 0.75       0.83333333 0.91666667 0.83333333]\n",
      "[1.         0.5        0.83333333 1.         1.        ]\n",
      "[0.6        1.         0.71428571 1.         1.        ]\n",
      "[0.75       0.6        0.76923077 0.90909091 0.90909091]\n",
      "Subject 14 Results with CV accuracy of 0.6 \n",
      "\n",
      "[0.5        0.33333333 0.66666667 0.83333333 0.66666667]\n",
      "[1.         0.16666667 0.33333333 0.83333333 0.5       ]\n",
      "[0.55555556 0.6        1.         0.83333333 0.66666667]\n",
      "[0.8        0.18181818 0.66666667 0.72727273 0.61538462]\n",
      "Subject 15 Results with CV accuracy of 0.4909090909090909 \n",
      "\n",
      "[0.66666667 0.75       0.58333333 0.36363636 0.09090909]\n",
      "[0.5        0.83333333 0.33333333 0.6        0.16666667]\n",
      "[0.8        0.71428571 0.66666667 0.375      0.16666667]\n",
      "[0.72727273 0.76923077 0.44444444 0.46153846 0.30769231]\n",
      "Subject 16 Results with CV accuracy of 0.7166666666666667 \n",
      "\n",
      "[0.41666667 0.75       0.75       0.75       0.91666667]\n",
      "[0.5        0.83333333 0.66666667 0.5        0.83333333]\n",
      "[0.42857143 0.71428571 0.75       1.         0.8       ]\n",
      "[0.57142857 0.76923077 0.6        0.66666667 0.83333333]\n",
      "Subject 17 Results with CV accuracy of 0.47435897435897434 \n",
      "\n",
      "[0.53846154 0.5        0.41666667 0.5        0.41666667]\n",
      "[0.66666667 0.16666667 0.66666667 0.83333333 0.5       ]\n",
      "[0.5        0.5        0.44444444 0.42857143 0.6       ]\n",
      "[0.57142857 0.25       0.5        0.66666667 0.54545455]\n",
      "Subject 18 Results with CV accuracy of 0.5166666666666667 \n",
      "\n",
      "[0.5        0.5        0.41666667 0.5        0.66666667]\n",
      "[0.5        0.33333333 0.66666667 0.66666667 1.        ]\n",
      "[0.5        0.5        0.33333333 0.5        0.66666667]\n",
      "[0.5        0.4        0.5        0.36363636 0.75      ]\n",
      "Subject 19 Results with CV accuracy of 0.6423076923076924 \n",
      "\n",
      "[0.61538462 0.69230769 0.53846154 0.61538462 0.75      ]\n",
      "[0.16666667 1.         0.71428571 0.57142857 0.83333333]\n",
      "[1.         0.77777778 0.75       1.         0.71428571]\n",
      "[0.25       0.77777778 0.8        0.72727273 0.625     ]\n",
      "Subject 20 Results with CV accuracy of 0.6833333333333333 \n",
      "\n",
      "[0.58333333 0.83333333 0.58333333 0.83333333 0.58333333]\n",
      "[0.5        1.         0.33333333 0.66666667 0.5       ]\n",
      "[0.6 1.  0.5 1.  0.6]\n",
      "[0.4        0.66666667 0.61538462 0.83333333 0.54545455]\n",
      "Subject 21 Results with CV accuracy of 0.6666666666666667 \n",
      "\n",
      "[0.41666667 0.5        1.         0.75       0.66666667]\n",
      "[0.66666667 0.16666667 0.66666667 0.66666667 0.66666667]\n",
      "[0.5        0.4        1.         0.8        0.66666667]\n",
      "[0.61538462 0.4        0.8        0.72727273 0.8       ]\n",
      "Subject 22 Results with CV accuracy of 0.55 \n",
      "\n",
      "[0.75 0.5  0.5  0.5  0.5 ]\n",
      "[0.83333333 0.66666667 0.33333333 0.66666667 0.5       ]\n",
      "[0.71428571 0.57142857 0.4        0.375      0.42857143]\n",
      "[0.76923077 0.61538462 0.36363636 0.57142857 0.57142857]\n",
      "Subject 23 Results with CV accuracy of 0.5166666666666667 \n",
      "\n",
      "[0.41666667 0.5        0.66666667 0.41666667 0.58333333]\n",
      "[0.66666667 0.5        0.83333333 0.33333333 0.66666667]\n",
      "[0.44444444 0.5        0.625      1.         0.6       ]\n",
      "[0.53333333 0.42857143 0.71428571 0.4        0.54545455]\n",
      "Subject 24 Results with CV accuracy of 0.65 \n",
      "\n",
      "[0.41666667 0.75       0.58333333 0.83333333 0.66666667]\n",
      "[0.83333333 0.66666667 0.5        1.         0.66666667]\n",
      "[0.5        0.8        0.66666667 0.75       0.66666667]\n",
      "[0.58823529 0.72727273 0.66666667 0.85714286 0.66666667]\n",
      "Subject 25 Results with CV accuracy of 0.4166666666666667 \n",
      "\n",
      "[0.41666667 0.16666667 0.58333333 0.33333333 0.58333333]\n",
      "[0.5        0.16666667 0.5        0.33333333 0.5       ]\n",
      "[0.42857143 0.16666667 0.33333333 0.2        0.5       ]\n",
      "[0.46153846 0.16666667 0.36363636 0.36363636 0.54545455]\n",
      "Subject 26 Results with CV accuracy of 0.5102564102564102 \n",
      "\n",
      "[0.38461538 0.41666667 0.58333333 0.5        0.66666667]\n",
      "[0.66666667 0.16666667 0.16666667 0.16666667 0.33333333]\n",
      "[0.4  0.25 0.6  0.5  1.  ]\n",
      "[0.5        0.36363636 0.54545455 0.22222222 0.25      ]\n",
      "Subject 27 Results with CV accuracy of 0.7833333333333334 \n",
      "\n",
      "[0.58333333 0.66666667 0.83333333 0.83333333 1.        ]\n",
      "[0.5        0.83333333 0.5        0.83333333 0.83333333]\n",
      "[0.6        0.57142857 0.75       0.83333333 0.85714286]\n",
      "[0.54545455 0.61538462 0.6        0.83333333 0.92307692]\n",
      "Subject 28 Results with CV accuracy of 0.45 \n",
      "\n",
      "[0.16666667 0.41666667 0.83333333 0.33333333 0.5       ]\n",
      "[0.16666667 0.5        0.83333333 0.5        0.66666667]\n",
      "[0.2  0.4  0.75 0.   0.5 ]\n",
      "[0.18181818 0.36363636 0.83333333 0.         0.46153846]\n",
      "Subject 29 Results with CV accuracy of 0.8 \n",
      "\n",
      "[0.58333333 0.83333333 0.91666667 0.91666667 0.75      ]\n",
      "[0.5        0.83333333 1.         1.         0.83333333]\n",
      "[0.6        0.83333333 0.85714286 0.75       0.71428571]\n",
      "[0.54545455 0.76923077 1.         0.8        0.76923077]\n",
      "Subject 30 Results with CV accuracy of 0.47820512820512817 \n",
      "\n",
      "[0.30769231 0.66666667 0.41666667 0.5        0.5       ]\n",
      "[0.33333333 0.83333333 0.33333333 0.5        0.66666667]\n",
      "[0.25       0.625      0.25       0.57142857 0.66666667]\n",
      "[0.4        0.71428571 0.22222222 0.4        0.54545455]\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "accuracy_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "f1_list = [] \n",
    "\n",
    "for i in range(1,31):\n",
    "    subject = math_relax_trim[math_relax_trim['id'] == i]\n",
    "    features = subject.drop(['label'], axis = 1)\n",
    "    scaled_data = scaler.fit_transform(features)\n",
    "    accuracy_all = cross_val_score(dtree, features, subject['label'], \n",
    "                             cv = 5, scoring = 'accuracy')\n",
    "    precision_all = cross_val_score(dtree, features, subject['label'], \n",
    "                             cv = 5, scoring = 'precision') \n",
    "    recall_all = cross_val_score(dtree, features, subject['label'], \n",
    "                             cv = 5, scoring = 'recall')\n",
    "    f1_all= cross_val_score(dtree, features, subject['label'], \n",
    "                             cv = 5, scoring = 'f1')\n",
    "    accuracy_list.append(accuracy_all.mean())\n",
    "    precision_list.append(precision_all.mean())\n",
    "    recall_list.append(recall_all.mean())\n",
    "    f1_list.append(f1_all.mean())\n",
    "    print(f'Subject {i} Results with CV accuracy of {accuracy_all.mean()} \\n')\n",
    "    print(accuracy_all)\n",
    "    print(recall_all)\n",
    "    print(precision_all)\n",
    "    print(f1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "precision = sum(precision_list)/len(precision_list)\n",
    "recall = sum(recall_list)/len(recall_list)\n",
    "f1 = sum(f1_list)/len(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.6146231546231548\n",
      "precision is 0.6456322751322753\n",
      "recall is 0.6282857142857142\n",
      "d1_score is 0.608011757305875\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy is {accuracy}')\n",
    "print(f'precision is {precision}')\n",
    "print(f'recall is {recall}')\n",
    "print(f'd1_score is {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Decision Tree, Math vs Relax, per Subject Cross Validation'\n",
    "\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=600)\n",
    "features = math_relax.drop(['Unnamed: 0', 'id', 'indra_time','reading_time', 'browser_latency', 'eeg_power', 'raw_values',\n",
    "       'signal_quality', 'createdAt', 'updatedAt', 'Session', 'Seen video before?', 'Chosen color',\n",
    "       'Saw icons?', 'Gender', 'Wear contacts','label'], axis = 1)\n",
    "scaled_data = scaler.fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,math_relax['label'], test_size=0.30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=600,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        math       0.69      0.67      0.68       292\n",
      "       relax       0.65      0.67      0.66       269\n",
      "\n",
      "    accuracy                           0.67       561\n",
      "   macro avg       0.67      0.67      0.67       561\n",
      "weighted avg       0.67      0.67      0.67       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 96 196]\n",
      " [ 75 194]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 67.20%\n",
      " Precision: 68.88%\n",
      "    Recall: 67.47%\n",
      "  F1 score: 68.17%\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy/precision/recall/f1\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = (accuracy_score(y_test, pred)).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Accuracy',accuracy))\n",
    "# precision tp / (tp + fp)\n",
    "precision = (precision_score(y_test, pred, pos_label = 'math' )).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Precision',precision))\n",
    "# recall: tp / (tp + fn)\n",
    "recall = (recall_score(y_test, pred, pos_label = 'math' )).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Recall',recall))\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = (f1_score(y_test, pred, pos_label = 'math' )).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('F1 score',f1))\n",
    "\n",
    "#ROC curve\n",
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred, pos_label = 'math' )\n",
    "# roc_auc = (auc(false_positive_rate, true_positive_rate)).astype('float64')\n",
    "# print('{:>10}: {:0.2%}'.format('ROC score',roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Random Forest'\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6304812834224599\n",
      "0.6396381389238082\n",
      "0.617387325554793\n",
      "0.6274276863014332\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rfc, scaled_data, math_relax['label'], \n",
    "                             cv = 10, scoring = 'accuracy')  \n",
    "accuracy = scores.mean()\n",
    "print(accuracy)\n",
    "\n",
    "precision_scores = cross_val_score(rfc, scaled_data, math_relax_trim['label'], \n",
    "                             cv = 10, scoring = 'precision') \n",
    "precision = precision_scores.mean()\n",
    "print(precision)\n",
    "\n",
    "recall_scores = cross_val_score(rfc, scaled_data, math_relax_trim['label'], \n",
    "                             cv = 10, scoring = 'recall') \n",
    "recall = recall_scores.mean()\n",
    "print(recall)\n",
    "\n",
    "f1_scores = cross_val_score(rfc, scaled_data, math_relax_trim['label'], \n",
    "                             cv = 10, scoring = 'f1') \n",
    "f1 = f1_scores.mean()\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Random Forest, Cross Validated'\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Per Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 Results with CV accuracy of 0.85 \n",
      "\n",
      "[0.91666667 0.83333333 0.91666667 1.         0.58333333]\n",
      "[0.83333333 1.         1.         1.         0.5       ]\n",
      "[0.85714286 0.66666667 0.85714286 1.         0.66666667]\n",
      "[0.83333333 0.8        0.92307692 1.         0.6       ]\n",
      "Subject 2 Results with CV accuracy of 0.5948717948717949 \n",
      "\n",
      "[0.30769231 0.75       0.66666667 0.58333333 0.66666667]\n",
      "[0.42857143 0.16666667 0.5        0.66666667 0.83333333]\n",
      "[0.375      0.8        0.6        0.57142857 0.625     ]\n",
      "[0.42857143 0.72727273 0.6        0.61538462 0.71428571]\n",
      "Subject 3 Results with CV accuracy of 0.8621212121212121 \n",
      "\n",
      "[0.91666667 0.83333333 1.         0.83333333 0.72727273]\n",
      "[0.83333333 1.         1.         1.         0.66666667]\n",
      "[1.         0.83333333 1.         0.77777778 0.8       ]\n",
      "[0.90909091 0.92307692 1.         0.875      0.72727273]\n",
      "Subject 4 Results with CV accuracy of 0.608974358974359 \n",
      "\n",
      "[0.84615385 0.61538462 0.58333333 0.5        0.5       ]\n",
      "[0.83333333 0.57142857 0.5        0.66666667 0.66666667]\n",
      "[0.83333333 0.66666667 0.6        0.5        0.5       ]\n",
      "[0.92307692 0.57142857 0.54545455 0.33333333 0.57142857]\n",
      "Subject 5 Results with CV accuracy of 0.791025641025641 \n",
      "\n",
      "[0.53846154 0.91666667 0.91666667 0.91666667 0.66666667]\n",
      "[1.         1.         0.83333333 1.         0.33333333]\n",
      "[0.5        0.85714286 1.         0.85714286 1.        ]\n",
      "[0.66666667 0.92307692 0.90909091 1.         0.5       ]\n",
      "Subject 6 Results with CV accuracy of 0.55 \n",
      "\n",
      "[0.75       0.58333333 0.66666667 0.33333333 0.41666667]\n",
      "[0.5        0.5        0.66666667 0.16666667 0.5       ]\n",
      "[1.         0.6        0.66666667 0.25       0.5       ]\n",
      "[0.66666667 0.5        0.66666667 0.2        0.46153846]\n",
      "Subject 7 Results with CV accuracy of 0.6756410256410257 \n",
      "\n",
      "[0.46153846 0.66666667 0.58333333 0.75       0.91666667]\n",
      "[0.66666667 0.83333333 0.66666667 0.66666667 0.66666667]\n",
      "[0.44444444 0.55555556 0.66666667 1.         1.        ]\n",
      "[0.53333333 0.71428571 0.66666667 0.72727273 0.8       ]\n",
      "Subject 8 Results with CV accuracy of 0.7500000000000001 \n",
      "\n",
      "[0.5        0.83333333 0.83333333 0.75       0.83333333]\n",
      "[0.5        0.83333333 1.         0.83333333 0.66666667]\n",
      "[0.42857143 0.85714286 0.75       0.71428571 1.        ]\n",
      "[0.5        0.76923077 0.8        0.8        0.8       ]\n",
      "Subject 9 Results with CV accuracy of 0.6166666666666667 \n",
      "\n",
      "[0.75       0.75       0.66666667 0.58333333 0.33333333]\n",
      "[0.5        0.83333333 0.83333333 0.83333333 0.5       ]\n",
      "[0.75       0.66666667 0.55555556 0.625      0.375     ]\n",
      "[0.66666667 0.8        0.66666667 0.71428571 0.33333333]\n",
      "Subject 10 Results with CV accuracy of 0.6666666666666666 \n",
      "\n",
      "[0.5        0.66666667 0.58333333 0.66666667 0.91666667]\n",
      "[0.5        0.5        0.83333333 0.83333333 1.        ]\n",
      "[0.5   0.75  0.625 0.625 1.   ]\n",
      "[0.54545455 0.6        0.66666667 0.71428571 0.90909091]\n",
      "Subject 11 Results with CV accuracy of 0.7269230769230769 \n",
      "\n",
      "[0.38461538 0.83333333 0.91666667 0.83333333 0.66666667]\n",
      "[0.5        1.         0.83333333 0.33333333 0.83333333]\n",
      "[0.375      0.85714286 1.         1.         0.625     ]\n",
      "[0.42857143 0.92307692 0.8        0.66666667 0.76923077]\n",
      "Subject 12 Results with CV accuracy of 0.6833333333333333 \n",
      "\n",
      "[0.5        0.83333333 0.75       0.83333333 0.5       ]\n",
      "[0.5        0.66666667 0.83333333 0.66666667 0.5       ]\n",
      "[0.6        0.83333333 0.71428571 0.6        0.5       ]\n",
      "[0.54545455 0.83333333 0.66666667 0.76923077 0.5       ]\n",
      "Subject 13 Results with CV accuracy of 0.9333333333333332 \n",
      "\n",
      "[0.66666667 1.         1.         1.         1.        ]\n",
      "[1. 1. 1. 1. 1.]\n",
      "[0.6 1.  1.  1.  1. ]\n",
      "[0.75 1.   1.   1.   1.  ]\n",
      "Subject 14 Results with CV accuracy of 0.7333333333333333 \n",
      "\n",
      "[0.75       0.66666667 0.66666667 0.83333333 0.75      ]\n",
      "[1.         0.66666667 0.33333333 0.83333333 1.        ]\n",
      "[0.66666667 0.66666667 1.         0.83333333 0.66666667]\n",
      "[0.8        0.66666667 0.5        0.90909091 0.76923077]\n",
      "Subject 15 Results with CV accuracy of 0.509090909090909 \n",
      "\n",
      "[0.66666667 0.66666667 0.66666667 0.18181818 0.36363636]\n",
      "[0.5        0.66666667 0.66666667 0.6        0.66666667]\n",
      "[0.75       0.57142857 0.66666667 0.375      0.42857143]\n",
      "[0.6        0.61538462 0.66666667 0.42857143 0.57142857]\n",
      "Subject 16 Results with CV accuracy of 0.75 \n",
      "\n",
      "[0.5        0.83333333 0.75       0.75       0.91666667]\n",
      "[0.66666667 0.83333333 0.66666667 0.66666667 0.83333333]\n",
      "[0.5        0.71428571 0.8        1.         1.        ]\n",
      "[0.57142857 0.76923077 0.72727273 0.66666667 0.90909091]\n",
      "Subject 17 Results with CV accuracy of 0.5269230769230769 \n",
      "\n",
      "[0.38461538 0.5        0.66666667 0.5        0.58333333]\n",
      "[0.66666667 0.16666667 0.5        0.66666667 0.66666667]\n",
      "[0.5  0.5  0.75 0.5  0.5 ]\n",
      "[0.57142857 0.25       0.6        0.66666667 0.57142857]\n",
      "Subject 18 Results with CV accuracy of 0.55 \n",
      "\n",
      "[0.58333333 0.5        0.41666667 0.41666667 0.83333333]\n",
      "[0.66666667 0.16666667 0.16666667 0.66666667 1.        ]\n",
      "[0.55555556 0.6        0.33333333 0.33333333 0.66666667]\n",
      "[0.66666667 0.22222222 0.22222222 0.22222222 0.75      ]\n",
      "Subject 19 Results with CV accuracy of 0.7807692307692309 \n",
      "\n",
      "[0.69230769 0.76923077 0.84615385 0.84615385 0.75      ]\n",
      "[0.33333333 1.         0.85714286 1.         0.83333333]\n",
      "[1.         0.7        0.85714286 0.77777778 1.        ]\n",
      "[0.5        0.82352941 0.85714286 0.875      0.8       ]\n",
      "Subject 20 Results with CV accuracy of 0.6 \n",
      "\n",
      "[0.5        0.83333333 0.5        0.66666667 0.5       ]\n",
      "[0.83333333 0.5        0.33333333 0.5        0.66666667]\n",
      "[0.5 1.  0.4 1.  0.5]\n",
      "[0.46153846 0.5        0.5        0.6        0.61538462]\n",
      "Subject 21 Results with CV accuracy of 0.7 \n",
      "\n",
      "[0.58333333 0.41666667 1.         0.75       0.75      ]\n",
      "[0.83333333 0.5        1.         0.66666667 0.66666667]\n",
      "[0.5        0.42857143 1.         1.         0.8       ]\n",
      "[0.66666667 0.46153846 1.         0.72727273 0.66666667]\n",
      "Subject 22 Results with CV accuracy of 0.4833333333333333 \n",
      "\n",
      "[0.75       0.58333333 0.5        0.41666667 0.16666667]\n",
      "[0.83333333 0.83333333 0.5        0.33333333 0.16666667]\n",
      "[0.66666667 0.57142857 0.66666667 0.4        0.16666667]\n",
      "[0.76923077 0.66666667 0.6        0.36363636 0.18181818]\n",
      "Subject 23 Results with CV accuracy of 0.5833333333333333 \n",
      "\n",
      "[0.33333333 0.41666667 0.66666667 0.58333333 0.91666667]\n",
      "[0.5        0.66666667 1.         0.5        0.83333333]\n",
      "[0.375 0.375 0.6   0.6   1.   ]\n",
      "[0.46153846 0.625      0.66666667 0.54545455 0.8       ]\n",
      "Subject 24 Results with CV accuracy of 0.7666666666666667 \n",
      "\n",
      "[0.58333333 0.83333333 0.66666667 1.         0.75      ]\n",
      "[1.         0.83333333 0.5        1.         0.66666667]\n",
      "[0.5  0.8  0.75 1.   1.  ]\n",
      "[0.70588235 0.83333333 0.54545455 1.         0.66666667]\n",
      "Subject 25 Results with CV accuracy of 0.35 \n",
      "\n",
      "[0.41666667 0.25       0.33333333 0.33333333 0.41666667]\n",
      "[0.33333333 0.16666667 0.33333333 0.66666667 0.33333333]\n",
      "[0.5        0.         0.33333333 0.57142857 0.4       ]\n",
      "[0.2        0.18181818 0.18181818 0.61538462 0.36363636]\n",
      "Subject 26 Results with CV accuracy of 0.3974358974358974 \n",
      "\n",
      "[0.15384615 0.41666667 0.5        0.58333333 0.33333333]\n",
      "[0.5        0.33333333 0.33333333 0.33333333 0.        ]\n",
      "[0.36363636 0.5        0.4        0.6        0.        ]\n",
      "[0.375      0.36363636 0.4        0.22222222 0.        ]\n",
      "Subject 27 Results with CV accuracy of 0.8 \n",
      "\n",
      "[0.75       0.91666667 0.83333333 0.75       0.75      ]\n",
      "[0.66666667 1.         0.83333333 0.5        1.        ]\n",
      "[0.8        0.75       0.83333333 1.         0.75      ]\n",
      "[0.83333333 0.92307692 0.83333333 0.66666667 0.85714286]\n",
      "Subject 28 Results with CV accuracy of 0.41666666666666663 \n",
      "\n",
      "[0.25       0.33333333 0.25       0.5        0.75      ]\n",
      "[0.16666667 0.16666667 0.16666667 0.66666667 0.66666667]\n",
      "[0.33333333 0.25       0.25       0.42857143 0.8       ]\n",
      "[0.33333333 0.2        0.2        0.5        0.66666667]\n",
      "Subject 29 Results with CV accuracy of 0.8833333333333334 \n",
      "\n",
      "[0.58333333 1.         1.         1.         0.83333333]\n",
      "[0.5 1.  1.  1.  1. ]\n",
      "[0.6  1.   1.   1.   0.75]\n",
      "[0.54545455 1.         1.         1.         0.85714286]\n",
      "Subject 30 Results with CV accuracy of 0.7102564102564103 \n",
      "\n",
      "[0.38461538 0.83333333 0.75       0.83333333 0.75      ]\n",
      "[0.5        1.         0.66666667 0.83333333 0.66666667]\n",
      "[0.4        0.75       0.57142857 0.83333333 0.8       ]\n",
      "[0.5        0.85714286 0.72727273 0.76923077 0.83333333]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "# features = math_relax.drop(['Unnamed: 0', 'id', 'indra_time','reading_time', 'browser_latency', 'eeg_power', 'raw_values',\n",
    "#        'signal_quality', 'createdAt', 'updatedAt', 'Session', 'Seen video before?', 'Chosen color',\n",
    "#        'Saw icons?', 'Gender', 'Wear contacts','label'], axis = 1)\n",
    "# scaled_data = scaler.fit_transform(features)\n",
    "accuracy_list = []\n",
    "\n",
    "for i in range(1,31):\n",
    "    subject = math_relax_trim[math_relax_trim['id'] == i]\n",
    "    features = subject.drop(['label'], axis = 1)\n",
    "    scaled_data = scaler.fit_transform(features)\n",
    "    accuracy_all = cross_val_score(rfc, features, subject['label'], \n",
    "                             cv = 5, scoring = 'accuracy')\n",
    "    precision_all = cross_val_score(rfc, features, subject['label'], \n",
    "                             cv = 5, scoring = 'precision') \n",
    "    recall_all = cross_val_score(rfc, features, subject['label'], \n",
    "                             cv = 5, scoring = 'recall')\n",
    "    f1_all= cross_val_score(rfc, features, subject['label'], \n",
    "                             cv = 5, scoring = 'f1')\n",
    "    accuracy_list.append(accuracy_all.mean())\n",
    "    precision_list.append(precision_all.mean())\n",
    "    recall_list.append(recall_all.mean())\n",
    "    f1_list.append(f1_all.mean())\n",
    "    print(f'Subject {i} Results with CV accuracy of {accuracy_all.mean()} \\n')\n",
    "    print(accuracy_all)\n",
    "    print(recall_all)\n",
    "    print(precision_all)\n",
    "    print(f1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "precision = sum(precision_list)/len(precision_list)\n",
    "recall = sum(recall_list)/len(recall_list)\n",
    "f1 = sum(f1_list)/len(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.6616899766899768\n",
      "precision is 0.6619369889369892\n",
      "recall is 0.6517777777777777\n",
      "d1_score is 0.630341162105868\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy is {accuracy}')\n",
    "print(f'precision is {precision}')\n",
    "print(f'recall is {recall}')\n",
    "print(f'd1_score is {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Random Forest, Math vs Relax, per Subject Cross Validation'\n",
    "\n",
    "acc = pd.read_csv(\"accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "# acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.to_csv(\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
